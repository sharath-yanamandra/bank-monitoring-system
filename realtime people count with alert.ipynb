{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from models.experimental import attempt_load\n",
    "from utils.general import non_max_suppression\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.cuda import amp\n",
    "import thop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting playsound\n",
      "  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: playsound\n",
      "  Building wheel for playsound (setup.py): started\n",
      "  Building wheel for playsound (setup.py): finished with status 'done'\n",
      "  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7044 sha256=0e2a2b4f298200a8abce0c4593dd1e2b7015b2d22245cd4956de297c2faf6dca\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\cf\\42\\ff\\7c587bae55eec67b909ca316b250d9b4daedbf272a3cbeb907\n",
      "Successfully built playsound\n",
      "Installing collected packages: playsound\n",
      "Successfully installed playsound-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using yolo basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 50.0ms\n",
      "Speed: 3.5ms preprocess, 50.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-27 11:58:49,329 - ERROR - \n",
      "    Error 259 for command:\n",
      "        play C:/Users/DELL/Downloads/beep-04.wav wait\n",
      "    The driver cannot recognize the specified command parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007\n",
      "\n",
      "0: 480x640 1 person, 6.0ms\n",
      "Speed: 2.4ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2.9ms\n",
      "Speed: 2.4ms preprocess, 2.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 0.0ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.3ms\n",
      "Speed: 2.3ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 0.0ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1.5ms\n",
      "Speed: 1.0ms preprocess, 1.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.9ms\n",
      "Speed: 0.0ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.1ms\n",
      "Speed: 2.6ms preprocess, 0.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.9ms\n",
      "Speed: 0.0ms preprocess, 3.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1.2ms\n",
      "Speed: 2.1ms preprocess, 1.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.4ms\n",
      "Speed: 2.3ms preprocess, 0.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 1.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 1.8ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1.1ms\n",
      "Speed: 1.9ms preprocess, 1.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.8ms\n",
      "Speed: 0.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.7ms\n",
      "Speed: 0.0ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.0ms\n",
      "Speed: 0.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 2.2ms preprocess, 0.0ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 4.8ms\n",
      "Speed: 0.0ms preprocess, 4.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.1ms\n",
      "Speed: 0.0ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.6ms\n",
      "Speed: 2.1ms preprocess, 3.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.9ms\n",
      "Speed: 0.0ms preprocess, 3.9ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.3ms preprocess, 8.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.9ms\n",
      "Speed: 0.0ms preprocess, 7.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 1.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.4ms\n",
      "Speed: 0.0ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.0ms\n",
      "Speed: 0.2ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.4ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.2ms\n",
      "Speed: 0.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 1.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 8.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.1ms\n",
      "Speed: 2.4ms preprocess, 11.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.0ms\n",
      "Speed: 0.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 0.0ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 3.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 2.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.1ms\n",
      "Speed: 0.0ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.8ms\n",
      "Speed: 2.1ms preprocess, 3.8ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.5ms\n",
      "Speed: 1.1ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.2ms\n",
      "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1.4ms\n",
      "Speed: 2.5ms preprocess, 1.4ms inference, 6.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 0.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 4.1ms\n",
      "Speed: 0.0ms preprocess, 4.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.1ms\n",
      "Speed: 0.0ms preprocess, 8.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 0.0ms preprocess, 9.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.5ms\n",
      "Speed: 2.7ms preprocess, 13.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.2ms\n",
      "Speed: 2.9ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 11.7ms\n",
      "Speed: 2.7ms preprocess, 11.7ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.0ms\n",
      "Speed: 3.1ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.8ms\n",
      "Speed: 0.0ms preprocess, 6.8ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 4.4ms\n",
      "Speed: 2.5ms preprocess, 4.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 2.6ms preprocess, 0.0ms inference, 7.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 2.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 2.3ms preprocess, 10.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.3ms\n",
      "Speed: 0.0ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.5ms\n",
      "Speed: 0.0ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.6ms\n",
      "Speed: 0.0ms preprocess, 10.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2.0ms\n",
      "Speed: 1.7ms preprocess, 2.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.6ms\n",
      "Speed: 0.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.4ms\n",
      "Speed: 0.0ms preprocess, 9.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.2ms\n",
      "Speed: 0.0ms preprocess, 6.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 3.7ms\n",
      "Speed: 0.0ms preprocess, 3.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.5ms\n",
      "Speed: 0.0ms preprocess, 7.5ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.9ms\n",
      "Speed: 0.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 4.3ms\n",
      "Speed: 0.0ms preprocess, 4.3ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.1ms\n",
      "Speed: 4.0ms preprocess, 7.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.3ms\n",
      "Speed: 0.0ms preprocess, 9.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.2ms\n",
      "Speed: 0.0ms preprocess, 9.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.6ms\n",
      "Speed: 0.0ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 5.5ms\n",
      "Speed: 0.0ms preprocess, 5.5ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.1ms\n",
      "Speed: 2.1ms preprocess, 10.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.8ms\n",
      "Speed: 3.7ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 10.9ms\n",
      "Speed: 0.0ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 2.1ms preprocess, 0.0ms inference, 8.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 8.5ms\n",
      "Speed: 0.0ms preprocess, 8.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 9.1ms\n",
      "Speed: 0.0ms preprocess, 9.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 7.4ms\n",
      "Speed: 0.0ms preprocess, 7.4ms inference, 4.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "#using yolo basic\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def play_alarm():\n",
    "    \"\"\"Play an alarm sound.\"\"\"\n",
    "    try:\n",
    "        # Replace this with the path to your alarm sound file\n",
    "        playsound('C:/Users/DELL/Downloads/beep-04.wav')\n",
    "    except:\n",
    "        print(\"\\a\")  # Fallback to system beep if sound file not found\n",
    "\n",
    "class RoomMonitor:\n",
    "    def __init__(self):\n",
    "        # Initialize the video capture\n",
    "        self.cap = cv2.VideoCapture(0)  # Use default camera (0)\n",
    "        \n",
    "        # Load the YOLO model\n",
    "        self.model = YOLO('yolov8n.pt')  # Using the smallest YOLOv8 model for speed\n",
    "        \n",
    "        # Initialize alert status\n",
    "        self.alert_active = False\n",
    "        self.last_alert_time = 0\n",
    "        self.alert_cooldown = 3  # Seconds between alerts\n",
    "        \n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Detect people in the frame using YOLO.\"\"\"\n",
    "        # Run YOLO detection\n",
    "        results = self.model(frame, conf=0.5)  # Confidence threshold of 0.5\n",
    "        \n",
    "        # Filter for person class (class 0 in COCO dataset)\n",
    "        people_boxes = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if box.cls == 0:  # Class 0 is person in COCO dataset\n",
    "                    people_boxes.append(box)\n",
    "        \n",
    "        return len(people_boxes), people_boxes\n",
    "    \n",
    "    def draw_boxes(self, frame, boxes, people_count):\n",
    "        \"\"\"Draw bounding boxes and labels on detected people.\"\"\"\n",
    "        for box in boxes:\n",
    "            # Get box coordinates\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            \n",
    "            # Determine the color of the bounding box\n",
    "            if people_count == 1 or people_count > 2:\n",
    "                box_color = (0, 0, 255)  # Red for 1 person or more than 2 people\n",
    "            elif people_count == 2:\n",
    "                box_color = (0, 255, 0)  # Green for exactly 2 people\n",
    "\n",
    "            # Draw rectangle with the appropriate color\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "            \n",
    "            # Add confidence score\n",
    "            conf = float(box.conf[0])\n",
    "            cv2.putText(frame, f'Person {conf:.2f}', (x1, y1 - 10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color, 2)\n",
    "    \n",
    "    def draw_status(self, frame, people_count):\n",
    "        \"\"\"Draw status information on the frame.\"\"\"\n",
    "        # Create status message\n",
    "        if people_count < 2:\n",
    "            status = f\"ALERT: Only {people_count} Need exactly 2 people.\"\n",
    "            status_color = (0, 0, 255)  # Red\n",
    "        elif people_count > 2:\n",
    "            status = f\"ALERT: {people_count} Maximum is 2 people.\"\n",
    "            status_color = (0, 0, 255)  # Red\n",
    "        else:\n",
    "            status = \"Status: OK (2 people detected)\"\n",
    "            status_color = (0, 255, 0)  # Green\n",
    "            \n",
    "        # Draw status text on the right side\n",
    "        cv2.putText(frame, status, (frame.shape[1] - 400, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)\n",
    "        \n",
    "        # Draw person count on the left side\n",
    "        cv2.putText(frame, f'People Count: {people_count}', (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)\n",
    "        \n",
    "        return status, status_color != (0, 255, 0)  # Return if alert needed\n",
    "    \n",
    "    def trigger_alert(self):\n",
    "        \"\"\"Trigger the alert sound in a separate thread.\"\"\"\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_alert_time >= self.alert_cooldown:\n",
    "            threading.Thread(target=play_alarm, daemon=True).start()\n",
    "            self.last_alert_time = current_time\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Main loop to run the monitoring system.\"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                # Read frame from camera\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"Error: Couldn't read from camera\")\n",
    "                    break\n",
    "                \n",
    "                # Detect people using YOLO\n",
    "                people_count, people_boxes = self.detect_people(frame)\n",
    "                \n",
    "                # Draw bounding boxes\n",
    "                self.draw_boxes(frame, people_boxes, people_count)\n",
    "                \n",
    "                # Update status display\n",
    "                status, need_alert = self.draw_status(frame, people_count)\n",
    "                \n",
    "                # Trigger alert if needed\n",
    "                if need_alert:\n",
    "                    self.trigger_alert()\n",
    "                \n",
    "                # Display the frame with default window size\n",
    "                cv2.imshow('Room Monitor (YOLOv8)', frame)\n",
    "                \n",
    "                # Break loop on 'q' press\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        finally:\n",
    "            # Clean up\n",
    "            self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    monitor = RoomMonitor()\n",
    "    monitor.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced ui and ux with recording cabability on webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:33,973 - INFO - Logging system initialized successfully\n",
      "2025-01-29 10:38:37,753 - INFO - Starting Vault Security System\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Speed: 4.0ms preprocess, 40.0ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:45,293 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:38:45,294 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:38:45,296 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:38:45,296 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-6 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:38:45,347 - INFO - Started recording violation clip: violation_clips\\violation_20250129_103845.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 2.3ms preprocess, 5.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.1ms\n",
      "Speed: 2.2ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.6ms\n",
      "Speed: 1.9ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.3ms\n",
      "Speed: 2.2ms preprocess, 3.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.2ms\n",
      "Speed: 2.0ms preprocess, 4.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.1ms\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.1ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 0.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 3.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20.5ms\n",
      "Speed: 3.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 2.1ms preprocess, 5.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.5ms\n",
      "Speed: 1.1ms preprocess, 5.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.3ms\n",
      "Speed: 1.1ms preprocess, 4.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 2.1ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.3ms\n",
      "Speed: 2.7ms preprocess, 4.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:48,302 - WARNING - Security violation detected: 1 people present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:48,352 - ERROR - \n",
      "    Error 275 for command:\n",
      "        open assets/alarm.wav\n",
      "    Cannot find the specified file.  Make sure the path and filename are correct.\n",
      "2025-01-29 10:38:48,354 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:38:48,354 - WARNING - Failed to close the file: assets/alarm.wav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-7 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 275 for command:\n",
      "        open assets/alarm.wav\n",
      "    Cannot find the specified file.  Make sure the path and filename are correct.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 2.1ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 0.9ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 1.0ms preprocess, 3.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.5ms\n",
      "Speed: 2.2ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.4ms\n",
      "Speed: 2.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.6ms\n",
      "Speed: 1.1ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.2ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.5ms\n",
      "Speed: 2.3ms preprocess, 5.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.6ms\n",
      "Speed: 2.3ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 2.1ms preprocess, 5.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.1ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.5ms\n",
      "Speed: 2.2ms preprocess, 6.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.2ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.1ms\n",
      "Speed: 2.0ms preprocess, 18.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 2.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.1ms\n",
      "Speed: 3.0ms preprocess, 12.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 2.1ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.1ms\n",
      "Speed: 2.0ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.1ms\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.6ms\n",
      "Speed: 1.1ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.1ms\n",
      "Speed: 2.0ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:51,308 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:38:51,321 - ERROR - \n",
      "    Error 275 for command:\n",
      "        open assets/alarm.wav\n",
      "    Cannot find the specified file.  Make sure the path and filename are correct.\n",
      "2025-01-29 10:38:51,322 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:38:51,323 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-8 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 275 for command:\n",
      "        open assets/alarm.wav\n",
      "    Cannot find the specified file.  Make sure the path and filename are correct.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.2ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.5ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.2ms\n",
      "Speed: 1.0ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 0.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.6ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 0.9ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:53,850 - INFO - Stopped recording violation clip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.5ms\n",
      "Speed: 1.1ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.9ms\n",
      "Speed: 1.0ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:54,599 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:38:54,610 - INFO - Started recording violation clip: violation_clips\\violation_20250129_103854.mp4\n",
      "2025-01-29 10:38:54,623 - ERROR - \n",
      "    Error 275 for command:\n",
      "        open assets/alarm.wav\n",
      "    Cannot find the specified file.  Make sure the path and filename are correct.\n",
      "2025-01-29 10:38:54,624 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:38:54,625 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-9 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 275 for command:\n",
      "        open assets/alarm.wav\n",
      "    Cannot find the specified file.  Make sure the path and filename are correct.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.5ms\n",
      "Speed: 1.1ms preprocess, 10.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.2ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.3ms\n",
      "Speed: 2.1ms preprocess, 7.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.5ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.0ms\n",
      "Speed: 3.1ms preprocess, 16.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 2.1ms preprocess, 15.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 25.1ms\n",
      "Speed: 2.0ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.9ms\n",
      "Speed: 3.1ms preprocess, 15.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11.9ms\n",
      "Speed: 2.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.2ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 0.9ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:38:56,540 - INFO - Stopped recording violation clip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.3ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 3.6ms\n",
      "Speed: 2.5ms preprocess, 3.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 15.0ms\n",
      "Speed: 5.0ms preprocess, 15.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.7ms\n",
      "Speed: 3.0ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.9ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.1ms\n",
      "Speed: 2.0ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.1ms\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.1ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.1ms\n",
      "Speed: 0.9ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.9ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.1ms\n",
      "Speed: 0.9ms preprocess, 4.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.7ms\n",
      "Speed: 1.0ms preprocess, 4.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.6ms\n",
      "Speed: 1.0ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.1ms\n",
      "Speed: 2.2ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.5ms\n",
      "Speed: 2.1ms preprocess, 4.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.2ms\n",
      "Speed: 2.2ms preprocess, 4.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 2.6ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.9ms\n",
      "Speed: 2.0ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.6ms\n",
      "Speed: 2.0ms preprocess, 5.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.9ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.1ms\n",
      "Speed: 0.9ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.5ms\n",
      "Speed: 1.0ms preprocess, 8.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.1ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.1ms\n",
      "Speed: 1.0ms preprocess, 7.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.5ms\n",
      "Speed: 1.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.1ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.5ms\n",
      "Speed: 2.0ms preprocess, 7.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.1ms\n",
      "Speed: 0.9ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.4ms\n",
      "Speed: 2.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 25.9ms\n",
      "Speed: 4.1ms preprocess, 25.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 21.0ms\n",
      "Speed: 3.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 22.5ms\n",
      "Speed: 2.0ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14.0ms\n",
      "Speed: 3.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:03,300 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:39:03,300 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:03,302 - INFO - Started recording violation clip: violation_clips\\violation_20250129_103903.mp4\n",
      "2025-01-29 10:39:03,302 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:03,303 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-10 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 2.1ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.1ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.3ms\n",
      "Speed: 1.0ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 1.1ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 1.1ms preprocess, 5.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.7ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.9ms\n",
      "Speed: 1.0ms preprocess, 5.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.9ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.9ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.2ms\n",
      "Speed: 2.1ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.4ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.4ms preprocess, 6.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:06,326 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:39:06,327 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:06,329 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:06,329 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-11 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.9ms preprocess, 15.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12.6ms\n",
      "Speed: 3.0ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 4.0ms preprocess, 13.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.6ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.6ms\n",
      "Speed: 1.0ms preprocess, 5.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.7ms\n",
      "Speed: 1.0ms preprocess, 5.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.1ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.1ms\n",
      "Speed: 3.0ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.6ms\n",
      "Speed: 3.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16.6ms\n",
      "Speed: 4.0ms preprocess, 16.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 24.5ms\n",
      "Speed: 3.0ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:09,386 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:39:09,386 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:09,388 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:09,389 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-12 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 3.9ms\n",
      "Speed: 2.0ms preprocess, 3.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.1ms\n",
      "Speed: 1.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.5ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.7ms\n",
      "Speed: 2.0ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.0ms preprocess, 5.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 1.9ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.4ms\n",
      "Speed: 2.2ms preprocess, 5.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.1ms\n",
      "Speed: 1.9ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.5ms\n",
      "Speed: 3.0ms preprocess, 13.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 24.9ms\n",
      "Speed: 2.1ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:11,372 - INFO - Stopped recording violation clip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 4.7ms\n",
      "Speed: 1.0ms preprocess, 4.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.1ms\n",
      "Speed: 1.9ms preprocess, 4.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.4ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.5ms\n",
      "Speed: 1.0ms preprocess, 5.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 4.3ms\n",
      "Speed: 2.1ms preprocess, 4.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:12,213 - INFO - Started recording violation clip: violation_clips\\violation_20250129_103912.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:12,394 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:39:12,394 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:12,397 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:12,397 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-13 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.1ms\n",
      "Speed: 2.1ms preprocess, 4.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.3ms\n",
      "Speed: 2.0ms preprocess, 5.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 3.5ms\n",
      "Speed: 2.0ms preprocess, 3.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.1ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.9ms\n",
      "Speed: 1.0ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.6ms\n",
      "Speed: 1.0ms preprocess, 7.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.3ms\n",
      "Speed: 0.9ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.2ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.1ms preprocess, 6.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.5ms\n",
      "Speed: 1.3ms preprocess, 6.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.3ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 2.0ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.1ms\n",
      "Speed: 1.0ms preprocess, 6.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 10.1ms\n",
      "Speed: 2.0ms preprocess, 10.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.2ms\n",
      "Speed: 2.3ms preprocess, 6.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.2ms\n",
      "Speed: 1.3ms preprocess, 6.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.9ms\n",
      "Speed: 1.1ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.5ms\n",
      "Speed: 1.0ms preprocess, 6.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.1ms\n",
      "Speed: 2.7ms preprocess, 29.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.4ms\n",
      "Speed: 2.1ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15.1ms\n",
      "Speed: 3.1ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.1ms\n",
      "Speed: 3.0ms preprocess, 13.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.5ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.4ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.1ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.0ms\n",
      "Speed: 2.3ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 10:39:15,403 - WARNING - Security violation detected: 1 people present\n",
      "2025-01-29 10:39:15,403 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:15,405 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-01-29 10:39:15,405 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-15 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 5.3ms\n",
      "Speed: 1.6ms preprocess, 5.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.6ms\n",
      "Speed: 1.0ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.1ms\n",
      "Speed: 0.5ms preprocess, 5.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.2ms\n",
      "Speed: 2.0ms preprocess, 4.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 1.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.0ms\n",
      "Speed: 1.6ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4.5ms\n",
      "Speed: 2.0ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#enhanced ui and ux with recording cabability\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class VaultSecuritySystem:\n",
    "    def __init__(self):\n",
    "        # Configuration\n",
    "        self.CONFIG = {\n",
    "            'required_people': 2,\n",
    "            'confidence_threshold': 0.6,\n",
    "            'alert_cooldown': 3,\n",
    "            'log_directory': 'vault_logs',\n",
    "            'alert_sounds': {\n",
    "                'violation': 'assets/alarm.wav',\n",
    "                'access_granted': 'assets/access_granted.wav'\n",
    "            },\n",
    "            'recording': {\n",
    "                'enabled': True,\n",
    "                'violation_clip_duration': 10,  # seconds\n",
    "                'output_directory': 'violation_clips'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Initialize logging\n",
    "        self._setup_logging()\n",
    "        \n",
    "        # Initialize the video capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.model = YOLO('yolov8n.pt')\n",
    "        \n",
    "        # State management\n",
    "        self.alert_active = False\n",
    "        self.last_alert_time = 0\n",
    "        self.current_violation_start = None\n",
    "        self.recording = False\n",
    "        \n",
    "        # Initialize violation recorder\n",
    "        self.violation_writer = None\n",
    "        \n",
    "        # Create required directories\n",
    "        self._create_directories()\n",
    "        \n",
    "        # Load custom UI elements\n",
    "        self._load_ui_elements()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configure logging system\"\"\"\n",
    "        try:\n",
    "            # Ensure the log directory exists\n",
    "            log_dir = Path(self.CONFIG['log_directory'])\n",
    "            log_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Create log file path\n",
    "            log_file = log_dir / f'vault_security_{datetime.now().strftime(\"%Y%m%d\")}.log'\n",
    "            \n",
    "            # Configure logging\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[\n",
    "                    logging.FileHandler(str(log_file)),\n",
    "                    logging.StreamHandler()\n",
    "                ]\n",
    "            )\n",
    "            self.logger = logging.getLogger('VaultSecurity')\n",
    "            self.logger.info('Logging system initialized successfully')\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up logging: {e}\")\n",
    "            # Fallback to basic logging if file logging fails\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[logging.StreamHandler()]\n",
    "            )\n",
    "            self.logger = logging.getLogger('VaultSecurity')\n",
    "\n",
    "    def _create_directories(self):\n",
    "        \"\"\"Create necessary directories for logs and recordings\"\"\"\n",
    "        os.makedirs(self.CONFIG['log_directory'], exist_ok=True)\n",
    "        os.makedirs(self.CONFIG['recording']['output_directory'], exist_ok=True)\n",
    "\n",
    "    def _load_ui_elements(self):\n",
    "        \"\"\"Load UI overlay elements\"\"\"\n",
    "        try:\n",
    "            # Create custom overlay elements\n",
    "            self.overlay_bg = np.zeros((100, 400, 3), dtype=np.uint8)\n",
    "            cv2.rectangle(self.overlay_bg, (0, 0), (400, 100), (20, 20, 20), -1)\n",
    "            \n",
    "            # Initialize status icons as None first\n",
    "            self.status_icons = {\n",
    "                'ok': None,\n",
    "                'warning': None,\n",
    "                'recording': None\n",
    "            }\n",
    "            \n",
    "            # Try to load icons if they exist, otherwise continue without them\n",
    "            icon_paths = {\n",
    "                'ok': 'assets/checkmark.png',\n",
    "                'warning': 'assets/warning.png',\n",
    "                'recording': 'assets/recording.png'\n",
    "            }\n",
    "            \n",
    "            for key, path in icon_paths.items():\n",
    "                try:\n",
    "                    if os.path.exists(path):\n",
    "                        self.status_icons[key] = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Could not load icon {path}: {e}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in UI element initialization: {e}\")\n",
    "\n",
    "    def draw_bounding_boxes(self, frame, people_boxes, people_count):\n",
    "        \"\"\"Draw color-coded bounding boxes around detected persons\"\"\"\n",
    "        # Determine box color based on number of people\n",
    "        if people_count == self.CONFIG['required_people']:\n",
    "            box_color = (0, 255, 0)  # Green for exactly 2 people (access granted)\n",
    "        else:\n",
    "            box_color = (0, 0, 255)  # Red for violations (1 person or >2 people)\n",
    "        \n",
    "        # Draw boxes around each detected person\n",
    "        for box in people_boxes:\n",
    "            # Get box coordinates\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "            \n",
    "            # Add confidence score with background\n",
    "            conf = float(box.conf[0])\n",
    "            conf_text = f'{conf:.2f}'\n",
    "            \n",
    "            # Get text size for background rectangle\n",
    "            (text_width, text_height), _ = cv2.getTextSize(\n",
    "                conf_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "            \n",
    "            # Draw background rectangle for text\n",
    "            cv2.rectangle(frame, \n",
    "                        (x1, y1 - text_height - 8), \n",
    "                        (x1 + text_width + 5, y1),\n",
    "                        box_color, -1)\n",
    "            \n",
    "            # Draw confidence text\n",
    "            cv2.putText(frame, conf_text,\n",
    "                       (x1 + 2, y1 - 5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       0.5, (255, 255, 255), 2)\n",
    "\n",
    "    def draw_professional_overlay(self, frame, people_count):\n",
    "        \"\"\"Draw professional UI overlay with vault security information\"\"\"\n",
    "        # Add semi-transparent dark overlay at the top\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "\n",
    "        # Add modern status display\n",
    "        status_text = f\"VAULT SECURITY STATUS: \"\n",
    "        if people_count == self.CONFIG['required_people']:\n",
    "            status = \"ACCESS GRANTED\"\n",
    "            color = (0, 255, 0)\n",
    "            icon = self.status_icons['ok']\n",
    "        else:\n",
    "            status = \"ACCESS DENIED\"\n",
    "            color = (0, 0, 255)\n",
    "            icon = self.status_icons['warning']\n",
    "\n",
    "        # Draw status text with professional styling and better positioning\n",
    "        cv2.putText(frame, status_text, (50, 50), \n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "        \n",
    "        # Move access status to bottom left\n",
    "        cv2.putText(frame, status, (50, 90),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, color, 2)\n",
    "\n",
    "        # Add time and date (moved to right side)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        cv2.putText(frame, f\"TIME: {current_time}\", (frame.shape[1] - 350, 50),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(frame, f\"DATE: {current_date}\", (frame.shape[1] - 350, 90),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "        # Add person count with icon (moved to center)\n",
    "        count_text = f\"PERSONS DETECTED: {people_count}/{self.CONFIG['required_people']}\"\n",
    "        text_size = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_DUPLEX, 1, 2)[0]\n",
    "        text_x = (frame.shape[1] - text_size[0]) // 2  # Center the text\n",
    "        cv2.putText(frame, count_text, (text_x, 50),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "\n",
    "        # Add recording indicator if active\n",
    "        if self.recording:\n",
    "            cv2.circle(frame, (frame.shape[1]-50, 50), 10, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"REC\", (frame.shape[1]-100, 50),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        return status != \"ACCESS GRANTED\"\n",
    "\n",
    "    def play_sound(self, sound_type):\n",
    "        \"\"\"Play appropriate sound based on the situation\"\"\"\n",
    "        try:\n",
    "            sound_file = self.CONFIG['alert_sounds'][sound_type]\n",
    "            threading.Thread(target=playsound, args=(sound_file,), daemon=True).start()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error playing sound: {e}\")\n",
    "            print('\\a')  # Fallback to system beep\n",
    "\n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Enhanced people detection with tracking\"\"\"\n",
    "        results = self.model(frame, conf=self.CONFIG['confidence_threshold'])\n",
    "        \n",
    "        people_boxes = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if box.cls == 0:  # Person class\n",
    "                    people_boxes.append(box)\n",
    "        \n",
    "        return len(people_boxes), people_boxes\n",
    "\n",
    "    def start_violation_recording(self, frame):\n",
    "        \"\"\"Start recording violation clip\"\"\"\n",
    "        if not self.recording:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = os.path.join(\n",
    "                self.CONFIG['recording']['output_directory'],\n",
    "                f'violation_{timestamp}.mp4'\n",
    "            )\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            self.violation_writer = cv2.VideoWriter(\n",
    "                output_path, fourcc, 20.0, \n",
    "                (frame.shape[1], frame.shape[0])\n",
    "            )\n",
    "            self.recording = True\n",
    "            self.current_violation_start = time.time()\n",
    "            self.logger.info(f\"Started recording violation clip: {output_path}\")\n",
    "\n",
    "    def stop_violation_recording(self):\n",
    "        \"\"\"Stop recording violation clip\"\"\"\n",
    "        if self.recording:\n",
    "            self.violation_writer.release()\n",
    "            self.recording = False\n",
    "            self.current_violation_start = None\n",
    "            self.logger.info(\"Stopped recording violation clip\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main monitoring loop with enhanced features\"\"\"\n",
    "        self.logger.info(\"Starting Vault Security System\")\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    self.logger.error(\"Failed to read from camera\")\n",
    "                    break\n",
    "\n",
    "                # Detect people\n",
    "                people_count, people_boxes = self.detect_people(frame)\n",
    "                \n",
    "                # Draw bounding boxes first (so they appear behind the overlay)\n",
    "                self.draw_bounding_boxes(frame, people_boxes, people_count)\n",
    "\n",
    "                # Draw professional UI\n",
    "                violation_detected = self.draw_professional_overlay(frame, people_count)\n",
    "\n",
    "                # Handle violations and recordings\n",
    "                if violation_detected:\n",
    "                    current_time = time.time()\n",
    "                    if current_time - self.last_alert_time >= self.CONFIG['alert_cooldown']:\n",
    "                        self.play_sound('violation')\n",
    "                        self.last_alert_time = current_time\n",
    "                        self.logger.warning(f\"Security violation detected: {people_count} people present\")\n",
    "\n",
    "                    if self.CONFIG['recording']['enabled']:\n",
    "                        self.start_violation_recording(frame)\n",
    "                        if self.recording:\n",
    "                            self.violation_writer.write(frame)\n",
    "                else:\n",
    "                    if self.recording:\n",
    "                        self.stop_violation_recording()\n",
    "\n",
    "                # Display the frame\n",
    "                cv2.imshow('Bank Vault Security Monitor', frame)\n",
    "\n",
    "                # Handle key presses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):  # Screenshot\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    cv2.imwrite(f'screenshot_{timestamp}.jpg', frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"System error: {e}\")\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.logger.info(\"Shutting down Vault Security System\")\n",
    "        if self.recording:\n",
    "            self.stop_violation_recording()\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vault_system = VaultSecuritySystem()\n",
    "    vault_system.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# on rtsp feed on cctv EZVIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:25,367 - INFO - Logging system initialized successfully\n",
      "2025-02-05 14:23:25,370 - INFO - Initializing RTSP camera connection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:27,575 - INFO - Successfully connected to RTSP stream\n",
      "2025-02-05 14:23:27,786 - INFO - Starting Vault Security System\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.4ms\n",
      "Speed: 3.6ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:29,560 - WARNING - Security violation detected: 1 people present\n",
      "2025-02-05 14:23:29,560 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:29,564 - INFO - Started recording violation clip: violation_clips\\violation_20250205_142329.mp4\n",
      "2025-02-05 14:23:29,565 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:29,565 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-54 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 14.0ms\n",
      "Speed: 1.1ms preprocess, 14.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 11.7ms\n",
      "Speed: 8.0ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.2ms\n",
      "Speed: 2.0ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.9ms\n",
      "Speed: 0.0ms preprocess, 17.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 13.2ms\n",
      "Speed: 2.6ms preprocess, 13.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.9ms\n",
      "Speed: 3.8ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.3ms\n",
      "Speed: 4.1ms preprocess, 19.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.4ms\n",
      "Speed: 0.0ms preprocess, 18.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 22.4ms\n",
      "Speed: 0.0ms preprocess, 22.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.3ms\n",
      "Speed: 0.0ms preprocess, 18.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 13.3ms\n",
      "Speed: 3.1ms preprocess, 13.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.5ms\n",
      "Speed: 0.8ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.6ms\n",
      "Speed: 0.6ms preprocess, 16.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 32.0ms\n",
      "Speed: 0.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.5ms\n",
      "Speed: 3.0ms preprocess, 17.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.6ms\n",
      "Speed: 0.0ms preprocess, 20.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 21.8ms\n",
      "Speed: 0.0ms preprocess, 21.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 15.8ms\n",
      "Speed: 3.4ms preprocess, 15.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 15.4ms\n",
      "Speed: 2.2ms preprocess, 15.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.4ms\n",
      "Speed: 0.0ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 18.8ms\n",
      "Speed: 0.0ms preprocess, 18.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.8ms\n",
      "Speed: 0.0ms preprocess, 16.8ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.8ms\n",
      "Speed: 0.0ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.3ms\n",
      "Speed: 3.0ms preprocess, 17.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.3ms\n",
      "Speed: 4.1ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.3ms\n",
      "Speed: 0.0ms preprocess, 19.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 11.9ms\n",
      "Speed: 7.9ms preprocess, 11.9ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.8ms\n",
      "Speed: 7.2ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.7ms\n",
      "Speed: 0.0ms preprocess, 19.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 15.6ms\n",
      "Speed: 7.0ms preprocess, 15.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.7ms\n",
      "Speed: 2.0ms preprocess, 17.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.7ms\n",
      "Speed: 4.7ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.0ms\n",
      "Speed: 3.6ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.1ms\n",
      "Speed: 3.7ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.4ms\n",
      "Speed: 0.0ms preprocess, 19.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.5ms\n",
      "Speed: 0.0ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.2ms\n",
      "Speed: 0.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 14.3ms\n",
      "Speed: 2.1ms preprocess, 14.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 20.4ms\n",
      "Speed: 0.0ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 16.5ms\n",
      "Speed: 3.9ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.7ms\n",
      "Speed: 0.0ms preprocess, 19.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 16.8ms\n",
      "Speed: 0.0ms preprocess, 16.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 22.9ms\n",
      "Speed: 0.0ms preprocess, 22.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 15.8ms\n",
      "Speed: 0.5ms preprocess, 15.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.7ms\n",
      "Speed: 3.7ms preprocess, 19.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.4ms\n",
      "Speed: 0.0ms preprocess, 19.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:32,595 - WARNING - Security violation detected: 1 people present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 31.8ms\n",
      "Speed: 0.0ms preprocess, 31.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.8ms\n",
      "Speed: 0.0ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.2ms\n",
      "Speed: 0.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.5ms\n",
      "Speed: 3.4ms preprocess, 16.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 22.3ms\n",
      "Speed: 0.0ms preprocess, 22.3ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.5ms\n",
      "Speed: 0.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.1ms\n",
      "Speed: 0.0ms preprocess, 18.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.0ms\n",
      "Speed: 0.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.7ms\n",
      "Speed: 4.5ms preprocess, 19.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.6ms\n",
      "Speed: 0.0ms preprocess, 17.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 15.9ms\n",
      "Speed: 0.5ms preprocess, 15.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.1ms\n",
      "Speed: 4.6ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 13.6ms\n",
      "Speed: 2.5ms preprocess, 13.6ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.6ms\n",
      "Speed: 0.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.5ms\n",
      "Speed: 0.0ms preprocess, 19.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 14.8ms\n",
      "Speed: 3.0ms preprocess, 14.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.1ms\n",
      "Speed: 0.0ms preprocess, 17.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.0ms\n",
      "Speed: 4.6ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.6ms\n",
      "Speed: 0.0ms preprocess, 20.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 21.6ms\n",
      "Speed: 0.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 21.7ms\n",
      "Speed: 0.0ms preprocess, 21.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.5ms\n",
      "Speed: 0.0ms preprocess, 18.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.7ms\n",
      "Speed: 0.0ms preprocess, 17.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.4ms\n",
      "Speed: 0.0ms preprocess, 20.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 22.7ms\n",
      "Speed: 0.0ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.7ms\n",
      "Speed: 0.0ms preprocess, 19.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.0ms\n",
      "Speed: 3.1ms preprocess, 17.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 16.9ms\n",
      "Speed: 4.5ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.7ms\n",
      "Speed: 0.0ms preprocess, 17.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 14.9ms\n",
      "Speed: 5.2ms preprocess, 14.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.2ms\n",
      "Speed: 4.8ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 0.0ms preprocess, 23.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.5ms\n",
      "Speed: 0.0ms preprocess, 20.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 26.4ms\n",
      "Speed: 0.0ms preprocess, 26.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.7ms\n",
      "Speed: 0.0ms preprocess, 19.7ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.9ms\n",
      "Speed: 0.0ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.5ms\n",
      "Speed: 0.0ms preprocess, 19.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 25.3ms\n",
      "Speed: 0.0ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 27.3ms\n",
      "Speed: 0.0ms preprocess, 27.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 18.1ms\n",
      "Speed: 5.7ms preprocess, 18.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:35,645 - WARNING - Security violation detected: 1 people present\n",
      "2025-02-05 14:23:35,645 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:35,645 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:35,645 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-56 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.4ms\n",
      "Speed: 0.0ms preprocess, 17.4ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 25.8ms\n",
      "Speed: 0.0ms preprocess, 25.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.1ms\n",
      "Speed: 9.1ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 26.3ms\n",
      "Speed: 0.0ms preprocess, 26.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 16.2ms\n",
      "Speed: 3.6ms preprocess, 16.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 22.9ms\n",
      "Speed: 0.0ms preprocess, 22.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.2ms\n",
      "Speed: 3.1ms preprocess, 20.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.2ms\n",
      "Speed: 0.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.1ms\n",
      "Speed: 4.6ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.8ms\n",
      "Speed: 0.0ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.8ms\n",
      "Speed: 0.0ms preprocess, 24.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 27.0ms\n",
      "Speed: 0.0ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.7ms\n",
      "Speed: 0.0ms preprocess, 19.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 20.7ms\n",
      "Speed: 3.8ms preprocess, 20.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.4ms\n",
      "Speed: 4.4ms preprocess, 20.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 26.7ms\n",
      "Speed: 0.0ms preprocess, 26.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 22.1ms\n",
      "Speed: 0.0ms preprocess, 22.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 26.3ms\n",
      "Speed: 0.0ms preprocess, 26.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.2ms\n",
      "Speed: 0.0ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.5ms\n",
      "Speed: 0.0ms preprocess, 19.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 21.3ms\n",
      "Speed: 0.0ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.5ms\n",
      "Speed: 0.0ms preprocess, 19.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.5ms\n",
      "Speed: 0.0ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 17.1ms\n",
      "Speed: 9.5ms preprocess, 17.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.8ms\n",
      "Speed: 7.8ms preprocess, 19.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.5ms\n",
      "Speed: 7.9ms preprocess, 19.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 27.4ms\n",
      "Speed: 0.0ms preprocess, 27.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.4ms\n",
      "Speed: 0.0ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.2ms\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.3ms\n",
      "Speed: 0.0ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 21.3ms\n",
      "Speed: 0.0ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.3ms\n",
      "Speed: 0.0ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.1ms\n",
      "Speed: 0.0ms preprocess, 23.1ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 16.9ms\n",
      "Speed: 7.1ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 17.2ms\n",
      "Speed: 6.6ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:38,695 - WARNING - Security violation detected: 1 people present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.1ms\n",
      "Speed: 6.6ms preprocess, 19.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.1ms\n",
      "Speed: 4.7ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 16.8ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.8ms\n",
      "Speed: 6.4ms preprocess, 17.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.8ms\n",
      "Speed: 6.6ms preprocess, 19.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.8ms\n",
      "Speed: 7.0ms preprocess, 19.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 18.2ms\n",
      "Speed: 6.4ms preprocess, 18.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 18.4ms\n",
      "Speed: 6.5ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.3ms\n",
      "Speed: 6.3ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 26.1ms\n",
      "Speed: 0.0ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.4ms\n",
      "Speed: 7.0ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.8ms\n",
      "Speed: 6.3ms preprocess, 17.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 16.9ms\n",
      "Speed: 6.9ms preprocess, 16.9ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 17.3ms\n",
      "Speed: 3.3ms preprocess, 17.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 17.1ms\n",
      "Speed: 6.5ms preprocess, 17.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 15.9ms\n",
      "Speed: 0.0ms preprocess, 15.9ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.7ms\n",
      "Speed: 0.0ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 21.9ms\n",
      "Speed: 6.4ms preprocess, 21.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.6ms\n",
      "Speed: 6.1ms preprocess, 20.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 17.3ms\n",
      "Speed: 3.7ms preprocess, 17.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 23.5ms\n",
      "Speed: 6.5ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 5 chairs, 26.6ms\n",
      "Speed: 0.0ms preprocess, 26.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 21.4ms\n",
      "Speed: 2.1ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 26.2ms\n",
      "Speed: 0.0ms preprocess, 26.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.5ms\n",
      "Speed: 0.5ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 26.6ms\n",
      "Speed: 0.0ms preprocess, 26.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 26.3ms\n",
      "Speed: 0.0ms preprocess, 26.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.6ms\n",
      "Speed: 1.2ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 20.9ms\n",
      "Speed: 0.0ms preprocess, 20.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 24.2ms\n",
      "Speed: 0.0ms preprocess, 24.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.4ms\n",
      "Speed: 2.0ms preprocess, 23.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 21.4ms\n",
      "Speed: 6.4ms preprocess, 21.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 17.2ms\n",
      "Speed: 5.9ms preprocess, 17.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 17.4ms\n",
      "Speed: 6.4ms preprocess, 17.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 1 laptop, 21.3ms\n",
      "Speed: 6.0ms preprocess, 21.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.1ms\n",
      "Speed: 6.4ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 21.8ms\n",
      "Speed: 6.3ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 20.8ms\n",
      "Speed: 6.0ms preprocess, 20.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.7ms\n",
      "Speed: 6.3ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 21.5ms\n",
      "Speed: 5.0ms preprocess, 21.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:41,761 - WARNING - Security violation detected: 1 people present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 18.0ms\n",
      "Speed: 1.6ms preprocess, 18.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 28.3ms\n",
      "Speed: 0.0ms preprocess, 28.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 25.1ms\n",
      "Speed: 0.0ms preprocess, 25.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.2ms\n",
      "Speed: 6.7ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 22.4ms\n",
      "Speed: 5.7ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 21.9ms\n",
      "Speed: 6.2ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.2ms\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.8ms\n",
      "Speed: 6.0ms preprocess, 23.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 27.8ms\n",
      "Speed: 0.0ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.7ms\n",
      "Speed: 6.1ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.6ms\n",
      "Speed: 0.8ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 24.4ms\n",
      "Speed: 0.0ms preprocess, 24.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 chairs, 1 laptop, 23.3ms\n",
      "Speed: 1.8ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 4 chairs, 24.0ms\n",
      "Speed: 2.8ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 26.8ms\n",
      "Speed: 0.0ms preprocess, 26.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 26.2ms\n",
      "Speed: 0.0ms preprocess, 26.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 24.0ms\n",
      "Speed: 0.0ms preprocess, 24.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 1 laptop, 26.6ms\n",
      "Speed: 0.0ms preprocess, 26.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 23.5ms\n",
      "Speed: 6.5ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 26.5ms\n",
      "Speed: 0.0ms preprocess, 26.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 17.4ms\n",
      "Speed: 5.8ms preprocess, 17.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 23.2ms\n",
      "Speed: 6.8ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 24.0ms\n",
      "Speed: 5.9ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 24.0ms\n",
      "Speed: 0.6ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 24.2ms\n",
      "Speed: 5.9ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 23.8ms\n",
      "Speed: 6.2ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 20.6ms\n",
      "Speed: 3.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 21.6ms\n",
      "Speed: 5.8ms preprocess, 21.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 17.0ms\n",
      "Speed: 5.3ms preprocess, 17.0ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 30.1ms\n",
      "Speed: 0.0ms preprocess, 30.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 26.7ms\n",
      "Speed: 0.0ms preprocess, 26.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 24.8ms\n",
      "Speed: 0.0ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 1 laptop, 23.3ms\n",
      "Speed: 5.3ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 1 laptop, 16.6ms\n",
      "Speed: 6.1ms preprocess, 16.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 1 laptop, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 19.9ms\n",
      "Speed: 6.5ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 1 laptop, 21.7ms\n",
      "Speed: 6.4ms preprocess, 21.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 1 laptop, 20.9ms\n",
      "Speed: 2.6ms preprocess, 20.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 22.2ms\n",
      "Speed: 0.0ms preprocess, 22.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 19.1ms\n",
      "Speed: 0.6ms preprocess, 19.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 20.8ms\n",
      "Speed: 0.0ms preprocess, 20.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 23.1ms\n",
      "Speed: 1.9ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 2 chairs, 22.9ms\n",
      "Speed: 0.0ms preprocess, 22.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 21.4ms\n",
      "Speed: 2.7ms preprocess, 21.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:44,795 - WARNING - Security violation detected: 1 people present\n",
      "2025-02-05 14:23:44,795 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:44,805 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:44,806 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-59 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 18.6ms\n",
      "Speed: 5.1ms preprocess, 18.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 17.1ms\n",
      "Speed: 1.9ms preprocess, 17.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 19.2ms\n",
      "Speed: 7.2ms preprocess, 19.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 23.4ms\n",
      "Speed: 0.0ms preprocess, 23.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 1 laptop, 18.8ms\n",
      "Speed: 5.9ms preprocess, 18.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 1 laptop, 21.1ms\n",
      "Speed: 1.9ms preprocess, 21.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 21.6ms\n",
      "Speed: 1.7ms preprocess, 21.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 16.9ms\n",
      "Speed: 4.4ms preprocess, 16.9ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 21.7ms\n",
      "Speed: 5.5ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 16.7ms\n",
      "Speed: 6.6ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 22.2ms\n",
      "Speed: 1.3ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 23.1ms\n",
      "Speed: 0.7ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 3 chairs, 1 laptop, 21.0ms\n",
      "Speed: 4.4ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 4 chairs, 1 laptop, 23.8ms\n",
      "Speed: 5.1ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 26.2ms\n",
      "Speed: 0.0ms preprocess, 26.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 19.5ms\n",
      "Speed: 0.2ms preprocess, 19.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 22.7ms\n",
      "Speed: 0.8ms preprocess, 22.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 24.0ms\n",
      "Speed: 3.6ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 22.2ms\n",
      "Speed: 4.2ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 26.5ms\n",
      "Speed: 0.0ms preprocess, 26.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 26.7ms\n",
      "Speed: 0.0ms preprocess, 26.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 23.1ms\n",
      "Speed: 0.6ms preprocess, 23.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 16.9ms\n",
      "Speed: 2.2ms preprocess, 16.9ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.8ms\n",
      "Speed: 0.0ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 19.8ms\n",
      "Speed: 5.6ms preprocess, 19.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 23.2ms\n",
      "Speed: 0.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 22.5ms\n",
      "Speed: 0.0ms preprocess, 22.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.0ms\n",
      "Speed: 0.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 22.5ms\n",
      "Speed: 1.0ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.1ms\n",
      "Speed: 5.8ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.9ms\n",
      "Speed: 6.5ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 17.1ms\n",
      "Speed: 5.7ms preprocess, 17.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 16.9ms\n",
      "Speed: 6.5ms preprocess, 16.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 17.0ms\n",
      "Speed: 5.9ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 20.9ms\n",
      "Speed: 1.5ms preprocess, 20.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 18.0ms\n",
      "Speed: 1.4ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 16.3ms\n",
      "Speed: 2.9ms preprocess, 16.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 16.8ms\n",
      "Speed: 6.4ms preprocess, 16.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 21.8ms\n",
      "Speed: 0.0ms preprocess, 21.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 17.2ms\n",
      "Speed: 6.5ms preprocess, 17.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 5 chairs, 1 laptop, 17.4ms\n",
      "Speed: 5.9ms preprocess, 17.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 20.3ms\n",
      "Speed: 2.2ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:47,904 - WARNING - Security violation detected: 1 people present\n",
      "2025-02-05 14:23:47,905 - ERROR - \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:47,908 - ERROR - \n",
      "    Error 263 for command:\n",
      "        close assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "2025-02-05 14:23:47,909 - WARNING - Failed to close the file: assets/alarm.wav\n",
      "Exception in thread Thread-60 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "    winCommand(u'open {}'.format(sound))\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    raise PlaysoundException(exceptionMessage)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open assets/alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 19.2ms\n",
      "Speed: 3.8ms preprocess, 19.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 1 laptop, 22.5ms\n",
      "Speed: 4.1ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 23.0ms\n",
      "Speed: 0.0ms preprocess, 23.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 17.0ms\n",
      "Speed: 5.6ms preprocess, 17.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 20.9ms\n",
      "Speed: 5.6ms preprocess, 20.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 20.1ms\n",
      "Speed: 3.1ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 21.3ms\n",
      "Speed: 3.7ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 1 laptop, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 20.4ms\n",
      "Speed: 6.3ms preprocess, 20.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 22.0ms\n",
      "Speed: 0.0ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.6ms\n",
      "Speed: 6.3ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.6ms\n",
      "Speed: 5.9ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.8ms\n",
      "Speed: 3.6ms preprocess, 19.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 19.4ms\n",
      "Speed: 0.0ms preprocess, 19.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 16.6ms\n",
      "Speed: 0.4ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 22.6ms\n",
      "Speed: 5.8ms preprocess, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 26.2ms\n",
      "Speed: 0.0ms preprocess, 26.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.4ms\n",
      "Speed: 5.9ms preprocess, 23.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 22.8ms\n",
      "Speed: 5.9ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.6ms\n",
      "Speed: 6.4ms preprocess, 23.6ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 20.9ms\n",
      "Speed: 0.0ms preprocess, 20.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 24.0ms\n",
      "Speed: 5.6ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.8ms\n",
      "Speed: 6.4ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.6ms\n",
      "Speed: 0.4ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 23.1ms\n",
      "Speed: 4.2ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 5 chairs, 23.4ms\n",
      "Speed: 6.7ms preprocess, 23.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 bottle, 5 chairs, 24.2ms\n",
      "Speed: 6.2ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 bottle, 5 chairs, 1 laptop, 20.3ms\n",
      "Speed: 3.8ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.4ms\n",
      "Speed: 2.2ms preprocess, 19.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.8ms\n",
      "Speed: 5.8ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 2.2ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.7ms\n",
      "Speed: 4.1ms preprocess, 23.7ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 6.0ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.1ms\n",
      "Speed: 6.2ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 19.9ms\n",
      "Speed: 2.6ms preprocess, 19.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.8ms\n",
      "Speed: 6.1ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.7ms\n",
      "Speed: 5.3ms preprocess, 23.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.5ms\n",
      "Speed: 0.0ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.8ms\n",
      "Speed: 5.5ms preprocess, 23.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.0ms\n",
      "Speed: 5.8ms preprocess, 24.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 6.1ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.1ms\n",
      "Speed: 6.6ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 0.5ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 22.4ms\n",
      "Speed: 1.7ms preprocess, 22.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:50,905 - WARNING - Security violation detected: 1 people present\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 chairs, 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.1ms\n",
      "Speed: 5.5ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 21.8ms\n",
      "Speed: 1.8ms preprocess, 21.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 22.1ms\n",
      "Speed: 3.6ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.6ms\n",
      "Speed: 3.1ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.8ms\n",
      "Speed: 3.1ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 22.9ms\n",
      "Speed: 0.0ms preprocess, 22.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.1ms\n",
      "Speed: 0.0ms preprocess, 24.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 chairs, 24.5ms\n",
      "Speed: 1.4ms preprocess, 24.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.3ms\n",
      "Speed: 0.9ms preprocess, 23.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.9ms\n",
      "Speed: 6.2ms preprocess, 24.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.2ms\n",
      "Speed: 6.0ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 6.1ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.9ms\n",
      "Speed: 6.3ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 25.9ms\n",
      "Speed: 3.6ms preprocess, 25.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 25.4ms\n",
      "Speed: 0.0ms preprocess, 25.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.2ms\n",
      "Speed: 5.7ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 25.8ms\n",
      "Speed: 0.0ms preprocess, 25.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 26.3ms\n",
      "Speed: 0.0ms preprocess, 26.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.6ms\n",
      "Speed: 6.2ms preprocess, 23.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.2ms\n",
      "Speed: 10.0ms preprocess, 23.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.3ms\n",
      "Speed: 4.5ms preprocess, 23.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 29.6ms\n",
      "Speed: 0.0ms preprocess, 29.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 22.1ms\n",
      "Speed: 3.3ms preprocess, 22.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.2ms\n",
      "Speed: 3.0ms preprocess, 23.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 22.6ms\n",
      "Speed: 3.1ms preprocess, 22.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 16.7ms\n",
      "Speed: 0.4ms preprocess, 16.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 21.3ms\n",
      "Speed: 5.5ms preprocess, 21.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.2ms\n",
      "Speed: 3.0ms preprocess, 20.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.6ms\n",
      "Speed: 0.0ms preprocess, 23.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 20.9ms\n",
      "Speed: 6.1ms preprocess, 20.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 5 chairs, 23.1ms\n",
      "Speed: 0.0ms preprocess, 23.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 14:23:53,198 - INFO - Shutting down Vault Security System\n",
      "2025-02-05 14:23:53,205 - INFO - Stopped recording violation clip\n"
     ]
    }
   ],
   "source": [
    "# on rtsp feed on cctv EZVIZ\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class VaultSecuritySystem:\n",
    "    def __init__(self):\n",
    "        # Configuration\n",
    "        self.CONFIG = {\n",
    "            'required_people': 2,\n",
    "            'confidence_threshold': 0.6,\n",
    "            'alert_cooldown': 3,\n",
    "            'log_directory': 'vault_logs',\n",
    "            'alert_sounds': {\n",
    "                'violation': 'assets/alarm.wav',\n",
    "                'access_granted': 'assets/access_granted.wav'\n",
    "            },\n",
    "            'recording': {\n",
    "                'enabled': True,\n",
    "                'violation_clip_duration': 10,  # seconds\n",
    "                'output_directory': 'violation_clips'\n",
    "            },\n",
    "            'camera': {\n",
    "                'rtsp_url': 'rtsp://admin:OUESEH@192.168.29.112:554/h264/ch1/main/av_stream',\n",
    "                'reconnect_attempts': 3,\n",
    "                'reconnect_delay': 2  # seconds between reconnection attempts\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Initialize logging\n",
    "        self._setup_logging()\n",
    "        \n",
    "        # Initialize the video capture with RTSP stream\n",
    "        self._initialize_camera()\n",
    "        \n",
    "        # Load YOLO model\n",
    "        self.model = YOLO('C:/Users/DELL/Desktop/south india bank/yolo11l.pt')\n",
    "        \n",
    "        # State management\n",
    "        self.alert_active = False\n",
    "        self.last_alert_time = 0\n",
    "        self.current_violation_start = None\n",
    "        self.recording = False\n",
    "        \n",
    "        # Initialize violation recorder\n",
    "        self.violation_writer = None\n",
    "        \n",
    "        # Create required directories\n",
    "        self._create_directories()\n",
    "        \n",
    "        # Load custom UI elements\n",
    "        self._load_ui_elements()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configure logging system\"\"\"\n",
    "        try:\n",
    "            # Ensure the log directory exists\n",
    "            log_dir = Path(self.CONFIG['log_directory'])\n",
    "            log_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Create log file path\n",
    "            log_file = log_dir / f'vault_security_{datetime.now().strftime(\"%Y%m%d\")}.log'\n",
    "            \n",
    "            # Configure logging\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[\n",
    "                    logging.FileHandler(str(log_file)),\n",
    "                    logging.StreamHandler()\n",
    "                ]\n",
    "            )\n",
    "            self.logger = logging.getLogger('VaultSecurity')\n",
    "            self.logger.info('Logging system initialized successfully')\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up logging: {e}\")\n",
    "            # Fallback to basic logging if file logging fails\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[logging.StreamHandler()]\n",
    "            )\n",
    "            self.logger = logging.getLogger('VaultSecurity')\n",
    "\n",
    "    def _create_directories(self):\n",
    "        \"\"\"Create necessary directories for logs and recordings\"\"\"\n",
    "        os.makedirs(self.CONFIG['log_directory'], exist_ok=True)\n",
    "        os.makedirs(self.CONFIG['recording']['output_directory'], exist_ok=True)\n",
    "\n",
    "    def _load_ui_elements(self):\n",
    "        \"\"\"Load UI overlay elements\"\"\"\n",
    "        try:\n",
    "            # Create custom overlay elements\n",
    "            self.overlay_bg = np.zeros((100, 400, 3), dtype=np.uint8)\n",
    "            cv2.rectangle(self.overlay_bg, (0, 0), (400, 100), (20, 20, 20), -1)\n",
    "            \n",
    "            # Initialize status icons as None first\n",
    "            self.status_icons = {\n",
    "                'ok': None,\n",
    "                'warning': None,\n",
    "                'recording': None\n",
    "            }\n",
    "            \n",
    "            # Try to load icons if they exist\n",
    "            icon_paths = {\n",
    "                'ok': 'assets/checkmark.png',\n",
    "                'warning': 'assets/warning.png',\n",
    "                'recording': 'assets/recording.png'\n",
    "            }\n",
    "            \n",
    "            for key, path in icon_paths.items():\n",
    "                try:\n",
    "                    if os.path.exists(path):\n",
    "                        self.status_icons[key] = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Could not load icon {path}: {e}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in UI element initialization: {e}\")\n",
    "\n",
    "    def _initialize_camera(self):\n",
    "        \"\"\"Initialize camera with RTSP stream and handle connection attempts\"\"\"\n",
    "        self.logger.info(\"Initializing RTSP camera connection...\")\n",
    "        \n",
    "        for attempt in range(self.CONFIG['camera']['reconnect_attempts']):\n",
    "            self.cap = cv2.VideoCapture(self.CONFIG['camera']['rtsp_url'])\n",
    "            \n",
    "            if self.cap.isOpened():\n",
    "                self.logger.info(\"Successfully connected to RTSP stream\")\n",
    "                # Set buffer size to minimize latency\n",
    "                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "                return\n",
    "            \n",
    "            self.logger.warning(f\"Failed to connect to RTSP stream (attempt {attempt + 1})\")\n",
    "            time.sleep(self.CONFIG['camera']['reconnect_delay'])\n",
    "        \n",
    "        self.logger.error(\"Failed to connect to RTSP stream after all attempts\")\n",
    "        raise ConnectionError(\"Could not connect to RTSP stream\")\n",
    "\n",
    "    def _reconnect_camera(self):\n",
    "        \"\"\"Attempt to reconnect to the RTSP stream if connection is lost\"\"\"\n",
    "        self.logger.warning(\"Attempting to reconnect to RTSP stream...\")\n",
    "        self.cap.release()\n",
    "        self._initialize_camera()\n",
    "\n",
    "    def draw_bounding_boxes(self, frame, people_boxes, people_count):\n",
    "        \"\"\"Draw color-coded bounding boxes around detected persons\"\"\"\n",
    "        # Determine box color based on number of people\n",
    "        if people_count == self.CONFIG['required_people']:\n",
    "            box_color = (0, 255, 0)  # Green for exactly 2 people (access granted)\n",
    "        else:\n",
    "            box_color = (0, 0, 255)  # Red for violations (1 person or >2 people)\n",
    "        \n",
    "        # Draw boxes around each detected person\n",
    "        for box in people_boxes:\n",
    "            # Get box coordinates\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            \n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "            \n",
    "            # Add confidence score with background\n",
    "            conf = float(box.conf[0])\n",
    "            conf_text = f'{conf:.2f}'\n",
    "            \n",
    "            # Get text size for background rectangle\n",
    "            (text_width, text_height), _ = cv2.getTextSize(\n",
    "                conf_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "            \n",
    "            # Draw background rectangle for text\n",
    "            cv2.rectangle(frame, \n",
    "                        (x1, y1 - text_height - 8), \n",
    "                        (x1 + text_width + 5, y1),\n",
    "                        box_color, -1)\n",
    "            \n",
    "            # Draw confidence text\n",
    "            cv2.putText(frame, conf_text,\n",
    "                       (x1 + 2, y1 - 5),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                       0.5, (255, 255, 255), 2)\n",
    "\n",
    "    def draw_professional_overlay(self, frame, people_count):\n",
    "        \"\"\"Draw professional UI overlay with vault security information\"\"\"\n",
    "        # Add semi-transparent dark overlay at the top\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "\n",
    "        # Add modern status display\n",
    "        status_text = f\"VAULT SECURITY: \"\n",
    "        if people_count == self.CONFIG['required_people']:\n",
    "            status = \"ACCESS GRANTED\"\n",
    "            color = (0, 255, 0)\n",
    "            icon = self.status_icons['ok']\n",
    "        else:\n",
    "            status = \"ACCESS DENIED\"\n",
    "            color = (0, 0, 255)\n",
    "            icon = self.status_icons['warning']\n",
    "\n",
    "        # Draw status text with professional styling\n",
    "        cv2.putText(frame, status_text, (50, 50), \n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "        \n",
    "        cv2.putText(frame, status, (50, 90),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, color, 2)\n",
    "\n",
    "        # Add time and date\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        cv2.putText(frame, f\"TIME: {current_time}\", (frame.shape[1] - 350, 50),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(frame, f\"DATE: {current_date}\", (frame.shape[1] - 350, 90),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "        # Add person count\n",
    "        count_text = f\"PERSONS DETECTED: {people_count}/{self.CONFIG['required_people']}\"\n",
    "        text_size = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_DUPLEX, 1, 2)[0]\n",
    "        text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "        cv2.putText(frame, count_text, (text_x, 50),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "\n",
    "        # Add recording indicator if active\n",
    "        if self.recording:\n",
    "            cv2.circle(frame, (frame.shape[1]-50, 50), 10, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"REC\", (frame.shape[1]-100, 50),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        return status != \"ACCESS GRANTED\"\n",
    "\n",
    "    def play_sound(self, sound_type):\n",
    "        \"\"\"Play appropriate sound based on the situation\"\"\"\n",
    "        try:\n",
    "            sound_file = self.CONFIG['alert_sounds'][sound_type]\n",
    "            threading.Thread(target=playsound, args=(sound_file,), daemon=True).start()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error playing sound: {e}\")\n",
    "            print('\\a')  # Fallback to system beep\n",
    "\n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Enhanced people detection with tracking\"\"\"\n",
    "        results = self.model(frame, conf=self.CONFIG['confidence_threshold'])\n",
    "        \n",
    "        people_boxes = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if box.cls == 0:  # Person class\n",
    "                    people_boxes.append(box)\n",
    "        \n",
    "        return len(people_boxes), people_boxes\n",
    "\n",
    "    def start_violation_recording(self, frame):\n",
    "        \"\"\"Start recording violation clip\"\"\"\n",
    "        if not self.recording:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = os.path.join(\n",
    "                self.CONFIG['recording']['output_directory'],\n",
    "                f'violation_{timestamp}.mp4'\n",
    "            )\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            self.violation_writer = cv2.VideoWriter(\n",
    "                output_path, fourcc, 20.0, \n",
    "                (frame.shape[1], frame.shape[0])\n",
    "            )\n",
    "            self.recording = True\n",
    "            self.current_violation_start = time.time()\n",
    "            self.logger.info(f\"Started recording violation clip: {output_path}\")\n",
    "\n",
    "    def stop_violation_recording(self):\n",
    "        \"\"\"Stop recording violation clip\"\"\"\n",
    "        if self.recording:\n",
    "            self.violation_writer.release()\n",
    "            self.recording = False\n",
    "            self.current_violation_start = None\n",
    "            self.logger.info(\"Stopped recording violation clip\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main monitoring loop with enhanced features and RTSP connection handling\"\"\"\n",
    "        self.logger.info(\"Starting Vault Security System\")\n",
    "        consecutive_failures = 0\n",
    "        max_failures = 5  # Maximum number of consecutive frame read failures before reconnecting\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                \n",
    "                if not ret:\n",
    "                    consecutive_failures += 1\n",
    "                    self.logger.warning(f\"Failed to read frame (failure {consecutive_failures})\")\n",
    "                    \n",
    "                    if consecutive_failures >= max_failures:\n",
    "                        self.logger.error(\"Multiple frame read failures, attempting to reconnect...\")\n",
    "                        try:\n",
    "                            self._reconnect_camera()\n",
    "                            consecutive_failures = 0\n",
    "                        except ConnectionError:\n",
    "                            self.logger.error(\"Failed to reconnect to camera\")\n",
    "                            break\n",
    "                    \n",
    "                    time.sleep(0.5)  # Brief pause before retry\n",
    "                    continue\n",
    "                \n",
    "                consecutive_failures = 0  # Reset failure counter on successful frame read\n",
    "\n",
    "                # Detect people\n",
    "                people_count, people_boxes = self.detect_people(frame)\n",
    "                \n",
    "                # Draw bounding boxes first (so they appear behind the overlay)\n",
    "                self.draw_bounding_boxes(frame, people_boxes, people_count)\n",
    "\n",
    "                # Draw professional UI\n",
    "                violation_detected = self.draw_professional_overlay(frame, people_count)\n",
    "\n",
    "                # Handle violations and recordings\n",
    "                if violation_detected:\n",
    "                    current_time = time.time()\n",
    "                    if current_time - self.last_alert_time >= self.CONFIG['alert_cooldown']:\n",
    "                        self.play_sound('violation')\n",
    "                        self.last_alert_time = current_time\n",
    "                        self.logger.warning(f\"Security violation detected: {people_count} people present\")\n",
    "\n",
    "                    if self.CONFIG['recording']['enabled']:\n",
    "                        self.start_violation_recording(frame)\n",
    "                        if self.recording:\n",
    "                            self.violation_writer.write(frame)\n",
    "                else:\n",
    "                    if self.recording:\n",
    "                        self.stop_violation_recording()\n",
    "\n",
    "                # Display the frame\n",
    "                cv2.imshow('Bank Vault Security Monitor', frame)\n",
    "\n",
    "                # Handle key presses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):  # Screenshot\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    cv2.imwrite(f'screenshot_{timestamp}.jpg', frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"System error: {e}\")\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.logger.info(\"Shutting down Vault Security System\")\n",
    "        if self.recording:\n",
    "            self.stop_violation_recording()\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    vault_system = VaultSecuritySystem()\n",
    "    vault_system.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More professional and polished look with Bank logo and click button to enter vault security system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyQt5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (5.15.10)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.13 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from PyQt5) (12.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyQt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:21:00,445 - INFO - Logging system initialized successfully\n",
      "2025-02-05 15:21:03,746 - INFO - Starting Vault Security System\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 20.3ms\n",
      "Speed: 4.0ms preprocess, 20.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:21:04,878 - WARNING - Security violation detected: 3 people present\n",
      "2025-02-05 15:21:04,878 - INFO - Made a temporary copy of C:/Users/DELL/Desktop/south india bank/assets/alarm.wav at C:\\Users\\DELL\\AppData\\Local\\Temp\\PSk4cgecjt.wav - use other filenames with only safe characters to avoid this.\n",
      "2025-02-05 15:21:04,881 - INFO - Started recording violation clip: violation_clips\\violation_20250205_152104.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 21.6ms\n",
      "Speed: 3.1ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.8ms\n",
      "Speed: 2.0ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19.7ms\n",
      "Speed: 2.0ms preprocess, 19.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.9ms\n",
      "Speed: 2.6ms preprocess, 18.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.3ms\n",
      "Speed: 2.0ms preprocess, 20.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.5ms\n",
      "Speed: 2.0ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.3ms\n",
      "Speed: 4.2ms preprocess, 37.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.5ms\n",
      "Speed: 2.8ms preprocess, 22.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:21:05,655 - ERROR - \n",
      "    Error 305 for command:\n",
      "        close \"C:\\Users\\DELL\\AppData\\Local\\Temp\\PSk4cgecjt.wav\"\n",
      "    Cannot specify extra characters after a string enclosed in quotation marks.\n",
      "2025-02-05 15:21:05,659 - WARNING - Failed to close the file: \"C:\\Users\\DELL\\AppData\\Local\\Temp\\PSk4cgecjt.wav\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 3 persons, 26.1ms\n",
      "Speed: 3.9ms preprocess, 26.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-64 (_playsoundWin):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\playsound.py\", line 46, in _playsoundWin\n",
      "    remove(tempPath)\n",
      "PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\DELL\\\\AppData\\\\Local\\\\Temp\\\\PSk4cgecjt.wav'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 34.4ms\n",
      "Speed: 3.1ms preprocess, 34.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19.5ms\n",
      "Speed: 2.1ms preprocess, 19.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 18.4ms\n",
      "Speed: 2.0ms preprocess, 18.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.6ms\n",
      "Speed: 3.1ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.5ms\n",
      "Speed: 2.1ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.6ms\n",
      "Speed: 3.0ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.8ms\n",
      "Speed: 2.1ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19.6ms\n",
      "Speed: 2.0ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.2ms\n",
      "Speed: 2.2ms preprocess, 22.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.5ms\n",
      "Speed: 3.0ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19.9ms\n",
      "Speed: 1.6ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.1ms\n",
      "Speed: 1.8ms preprocess, 22.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23.8ms\n",
      "Speed: 3.1ms preprocess, 23.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23.3ms\n",
      "Speed: 3.5ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.9ms\n",
      "Speed: 2.1ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.6ms\n",
      "Speed: 2.0ms preprocess, 22.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.0ms\n",
      "Speed: 4.2ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 19.9ms\n",
      "Speed: 2.0ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.9ms\n",
      "Speed: 2.1ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.9ms\n",
      "Speed: 1.7ms preprocess, 21.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.6ms\n",
      "Speed: 3.0ms preprocess, 22.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.1ms\n",
      "Speed: 3.8ms preprocess, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23.3ms\n",
      "Speed: 2.0ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 24.6ms\n",
      "Speed: 3.8ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.0ms\n",
      "Speed: 3.2ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.7ms\n",
      "Speed: 1.0ms preprocess, 22.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 28.5ms\n",
      "Speed: 3.0ms preprocess, 28.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23.2ms\n",
      "Speed: 3.5ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:21:07,912 - WARNING - Security violation detected: 3 people present\n",
      "2025-02-05 15:21:07,912 - INFO - Made a temporary copy of C:/Users/DELL/Desktop/south india bank/assets/alarm.wav at C:\\Users\\DELL\\AppData\\Local\\Temp\\PSy3y82xu7.wav - use other filenames with only safe characters to avoid this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 persons, 22.4ms\n",
      "Speed: 3.0ms preprocess, 22.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.1ms\n",
      "Speed: 3.0ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.0ms\n",
      "Speed: 3.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.5ms\n",
      "Speed: 3.0ms preprocess, 22.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.7ms\n",
      "Speed: 2.0ms preprocess, 21.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 23.0ms\n",
      "Speed: 2.5ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 21.0ms\n",
      "Speed: 3.0ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 22.5ms\n",
      "Speed: 3.5ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.7ms\n",
      "Speed: 3.3ms preprocess, 20.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 20.5ms\n",
      "Speed: 2.9ms preprocess, 20.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 15:21:08,708 - INFO - Shutting down Vault Security System\n",
      "2025-02-05 15:21:08,710 - INFO - Stopped recording violation clip\n",
      "2025-02-05 15:21:09,049 - INFO - Shutting down Vault Security System\n",
      "2025-02-05 15:21:09,051 - INFO - Shutting down Vault Security System\n",
      "2025-02-05 15:21:09,052 - INFO - Shutting down Vault Security System\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "#works with front camera of laptop\n",
    "import sys\n",
    "from PyQt5.QtWidgets import (QApplication, QMainWindow, QPushButton, QLabel, QVBoxLayout, QWidget)\n",
    "from PyQt5.QtGui import QPixmap, QFont, QPalette, QColor\n",
    "from PyQt5.QtCore import Qt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class BankSecurityApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"South India Bank - Security System\")\n",
    "        self.setFixedSize(800, 600)\n",
    "\n",
    "        # Set window background color to a professional banking blue\n",
    "        palette = self.palette()\n",
    "        palette.setColor(QPalette.Window, QColor('#f5f5f5'))\n",
    "        self.setPalette(palette)\n",
    "\n",
    "        # Create central widget and layout\n",
    "        central_widget = QWidget()\n",
    "        self.setCentralWidget(central_widget)\n",
    "        layout = QVBoxLayout(central_widget)\n",
    "        layout.setAlignment(Qt.AlignCenter)\n",
    "        layout.setSpacing(20)\n",
    "\n",
    "        # Add bank logo\n",
    "        logo_label = QLabel()\n",
    "        logo_pixmap = QPixmap('assets/bank_logo.png')  # Ensure this path is correct\n",
    "        scaled_pixmap = logo_pixmap.scaled(300, 300, Qt.KeepAspectRatio, Qt.SmoothTransformation)\n",
    "        logo_label.setPixmap(scaled_pixmap)\n",
    "        logo_label.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(logo_label)\n",
    "\n",
    "        # Add bank name with professional styling\n",
    "        bank_name = QLabel(\"SOUTH INDIA BANK\")\n",
    "        bank_name.setFont(QFont('Arial', 24, QFont.Bold))\n",
    "        bank_name.setStyleSheet(\"color: #00205b;\")  # Dark blue color\n",
    "        bank_name.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(bank_name)\n",
    "\n",
    "        # Add security system tagline\n",
    "        tagline = QLabel(\"Advanced Vault Security System\")\n",
    "        tagline.setFont(QFont('Arial', 14))\n",
    "        tagline.setStyleSheet(\"color: #666666;\")\n",
    "        tagline.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(tagline)\n",
    "\n",
    "        # Add enter button with professional styling\n",
    "        self.enter_button = QPushButton(\"Enter Vault Security System\")\n",
    "        self.enter_button.setFont(QFont('Arial', 12))\n",
    "        self.enter_button.setStyleSheet(\"\"\"\n",
    "            QPushButton {\n",
    "                background-color: #00205b;\n",
    "                color: white;\n",
    "                border: none;\n",
    "                padding: 15px 30px;\n",
    "                border-radius: 5px;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #003080;\n",
    "            }\n",
    "            QPushButton:pressed {\n",
    "                background-color: #001540;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.enter_button.setFixedWidth(300)\n",
    "        self.enter_button.clicked.connect(self.launch_security_system)\n",
    "        layout.addWidget(self.enter_button)\n",
    "\n",
    "        # Add copyright notice\n",
    "        copyright_label = QLabel(f\" {datetime.now().year} South India Bank. All rights reserved.\")\n",
    "        copyright_label.setFont(QFont('Arial', 8))\n",
    "        copyright_label.setStyleSheet(\"color: #999999;\")\n",
    "        copyright_label.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(copyright_label)\n",
    "\n",
    "        # Initialize vault system as None\n",
    "        self.vault_system = None\n",
    "\n",
    "    def launch_security_system(self):\n",
    "        \"\"\"Launch the vault security system\"\"\"\n",
    "        self.hide()  # Hide the main window\n",
    "        self.vault_system = VaultSecuritySystem(parent_app=self)\n",
    "        try:\n",
    "            self.vault_system.run()\n",
    "        except SystemExit:\n",
    "            self.close()  # Close the main window if system exit is triggered\n",
    "        except Exception as e:\n",
    "            print(f\"Error in security system: {e}\")\n",
    "            self.show()  # Show the main window again on error\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"Handle application closure\"\"\"\n",
    "        if self.vault_system:\n",
    "            self.vault_system.cleanup()\n",
    "        event.accept()\n",
    "\n",
    "\n",
    "class VaultSecuritySystem:\n",
    "    def __init__(self, parent_app=None):\n",
    "        self.parent_app = parent_app  # Reference to the main application window\n",
    "\n",
    "        # Configuration\n",
    "        self.CONFIG = {\n",
    "            'required_people': 2,\n",
    "            'confidence_threshold': 0.6,\n",
    "            'alert_cooldown': 3,\n",
    "            'log_directory': 'vault_logs',\n",
    "            'alert_sounds': {\n",
    "                'violation': 'C:/Users/DELL/Desktop/south india bank/assets/alarm.wav',\n",
    "                'access_granted': 'C:/Users/DELL/Desktop/south india bank/assets/access-granted.mp3v'\n",
    "            },\n",
    "            'recording': {\n",
    "                'enabled': True,\n",
    "                'violation_clip_duration': 10,  # seconds\n",
    "                'output_directory': 'violation_clips'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Initialize logging\n",
    "        self._setup_logging()\n",
    "\n",
    "        # Initialize the video capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "        # Load YOLO model\n",
    "        self.model = YOLO('C:/Users/DELL/Desktop/south india bank/yolo11l.pt')  # Ensure this path is correct\n",
    "\n",
    "        # State management\n",
    "        self.alert_active = False\n",
    "        self.last_alert_time = 0\n",
    "        self.current_violation_start = None\n",
    "        self.recording = False\n",
    "\n",
    "        # Initialize violation recorder\n",
    "        self.violation_writer = None\n",
    "\n",
    "        # Create required directories\n",
    "        self._create_directories()\n",
    "\n",
    "        # Load custom UI elements\n",
    "        self._load_ui_elements()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configure logging system\"\"\"\n",
    "        try:\n",
    "            # Ensure the log directory exists\n",
    "            log_dir = Path(self.CONFIG['log_directory'])\n",
    "            log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Create log file path\n",
    "            log_file = log_dir / f'vault_security_{datetime.now().strftime(\"%Y%m%d\")}.log'\n",
    "\n",
    "            # Configure logging\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[\n",
    "                    logging.FileHandler(str(log_file)),\n",
    "                    logging.StreamHandler()\n",
    "                ]\n",
    "            )\n",
    "            self.logger = logging.getLogger('VaultSecurity')\n",
    "            self.logger.info('Logging system initialized successfully')\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up logging: {e}\")\n",
    "            # Fallback to basic logging if file logging fails\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[logging.StreamHandler()]\n",
    "            )\n",
    "            self.logger = logging.getLogger('VaultSecurity')\n",
    "\n",
    "    def _create_directories(self):\n",
    "        \"\"\"Create necessary directories for logs and recordings\"\"\"\n",
    "        os.makedirs(self.CONFIG['log_directory'], exist_ok=True)\n",
    "        os.makedirs(self.CONFIG['recording']['output_directory'], exist_ok=True)\n",
    "\n",
    "    def _load_ui_elements(self):\n",
    "        \"\"\"Load UI overlay elements\"\"\"\n",
    "        try:\n",
    "            # Create custom overlay elements\n",
    "            self.overlay_bg = np.zeros((100, 400, 3), dtype=np.uint8)\n",
    "            cv2.rectangle(self.overlay_bg, (0, 0), (400, 100), (20, 20, 20), -1)\n",
    "\n",
    "            # Initialize status icons as None first\n",
    "            self.status_icons = {\n",
    "                'ok': None,\n",
    "                'warning': None,\n",
    "                'recording': None\n",
    "            }\n",
    "\n",
    "            # Try to load icons if they exist, otherwise continue without them\n",
    "            icon_paths = {\n",
    "                'ok': 'C:/Users/DELL/Desktop/south india bank/assets/checkmark.png',\n",
    "                'warning': 'C:/Users/DELL/Desktop/south india bank/assets/warning.png',\n",
    "                'recording': 'C:/Users/DELL/Desktop/south india bank/assets/recording.png'\n",
    "            }\n",
    "\n",
    "            for key, path in icon_paths.items():\n",
    "                try:\n",
    "                    if os.path.exists(path):\n",
    "                        self.status_icons[key] = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Could not load icon {path}: {e}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in UI element initialization: {e}\")\n",
    "\n",
    "    def draw_bounding_boxes(self, frame, people_boxes, people_count):\n",
    "        \"\"\"Draw color-coded bounding boxes around detected persons\"\"\"\n",
    "        # Determine box color based on number of people\n",
    "        if people_count == self.CONFIG['required_people']:\n",
    "            box_color = (0, 255, 0)  # Green for exactly 2 people (access granted)\n",
    "        else:\n",
    "            box_color = (0, 0, 255)  # Red for violations (1 person or >2 people)\n",
    "\n",
    "        # Draw boxes around each detected person\n",
    "        for box in people_boxes:\n",
    "            # Get box coordinates\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Draw rectangle\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "\n",
    "            # Add confidence score with background\n",
    "            conf = float(box.conf[0])\n",
    "            conf_text = f'{conf:.2f}'\n",
    "\n",
    "            # Get text size for background rectangle\n",
    "            (text_width, text_height), _ = cv2.getTextSize(\n",
    "                conf_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "\n",
    "            # Draw background rectangle for text\n",
    "            cv2.rectangle(frame,\n",
    "                          (x1, y1 - text_height - 8),\n",
    "                          (x1 + text_width + 5, y1),\n",
    "                          box_color, -1)\n",
    "\n",
    "            # Draw confidence text\n",
    "            cv2.putText(frame, conf_text,\n",
    "                        (x1 + 2, y1 - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5, (255, 255, 255), 2)\n",
    "\n",
    "    def draw_professional_overlay(self, frame, people_count):\n",
    "        \"\"\"Draw professional UI overlay with vault security information\"\"\"\n",
    "        # Add semi-transparent dark overlay at the top\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "\n",
    "        # Add modern status display\n",
    "        status_text = f\"VAULT SECURITY STATUS: \"\n",
    "        if people_count == self.CONFIG['required_people']:\n",
    "            status = \"ACCESS GRANTED\"\n",
    "            color = (0, 255, 0)\n",
    "            icon = self.status_icons['ok']\n",
    "        else:\n",
    "            status = \"ACCESS DENIED\"\n",
    "            color = (0, 0, 255)\n",
    "            icon = self.status_icons['warning']\n",
    "\n",
    "        # Draw status text with professional styling and better positioning\n",
    "        cv2.putText(frame, status_text, (50, 50),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "\n",
    "        # Move access status to bottom left\n",
    "        cv2.putText(frame, status, (50, 90),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1, color, 2)\n",
    "\n",
    "        # Add time and date (moved to right side)\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        cv2.putText(frame, f\"TIME: {current_time}\", (frame.shape[1] - 350, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(frame, f\"DATE: {current_date}\", (frame.shape[1] - 350, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "        # Add person count with icon (moved to center)\n",
    "        count_text = f\"PERSONS DETECTED: {people_count}/{self.CONFIG['required_people']}\"\n",
    "        text_size = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_DUPLEX, 1, 2)[0]\n",
    "        text_x = (frame.shape[1] - text_size[0]) // 2  # Center the text\n",
    "        cv2.putText(frame, count_text, (text_x, 50),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "\n",
    "        # Add recording indicator if active\n",
    "        if self.recording:\n",
    "            cv2.circle(frame, (frame.shape[1] - 50, 50), 10, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"REC\", (frame.shape[1] - 100, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        return status != \"ACCESS GRANTED\"\n",
    "\n",
    "    def play_sound(self, sound_type):\n",
    "        \"\"\"Play appropriate sound based on the situation\"\"\"\n",
    "        try:\n",
    "            sound_file = self.CONFIG['alert_sounds'][sound_type]\n",
    "            threading.Thread(target=playsound, args=(sound_file,), daemon=True).start()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error playing sound: {e}\")\n",
    "            print('\\a')  # Fallback to system beep\n",
    "\n",
    "    def detect_people(self, frame):\n",
    "        \"\"\"Enhanced people detection with tracking\"\"\"\n",
    "        results = self.model(frame, conf=self.CONFIG['confidence_threshold'])\n",
    "\n",
    "        people_boxes = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if box.cls == 0:  # Person class\n",
    "                    people_boxes.append(box)\n",
    "\n",
    "        return len(people_boxes), people_boxes\n",
    "\n",
    "    def start_violation_recording(self, frame):\n",
    "        \"\"\"Start recording violation clip\"\"\"\n",
    "        if not self.recording:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            output_path = os.path.join(\n",
    "                self.CONFIG['recording']['output_directory'],\n",
    "                f'violation_{timestamp}.mp4'\n",
    "            )\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            self.violation_writer = cv2.VideoWriter(\n",
    "                output_path, fourcc, 20.0,\n",
    "                (frame.shape[1], frame.shape[0])\n",
    "            )\n",
    "            self.recording = True\n",
    "            self.current_violation_start = time.time()\n",
    "            self.logger.info(f\"Started recording violation clip: {output_path}\")\n",
    "\n",
    "    def stop_violation_recording(self):\n",
    "        \"\"\"Stop recording violation clip\"\"\"\n",
    "        if self.recording:\n",
    "            self.violation_writer.release()\n",
    "            self.recording = False\n",
    "            self.current_violation_start = None\n",
    "            self.logger.info(\"Stopped recording violation clip\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Main monitoring loop with enhanced features and RTSP connection handling\"\"\"\n",
    "        self.logger.info(\"Starting Vault Security System\")\n",
    "        consecutive_failures = 0\n",
    "        max_failures = 5\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    consecutive_failures += 1\n",
    "                    self.logger.warning(f\"Failed to read frame (failure {consecutive_failures})\")\n",
    "\n",
    "                    if consecutive_failures >= max_failures:\n",
    "                        self.logger.error(\"Multiple frame read failures, attempting to reconnect...\")\n",
    "                        try:\n",
    "                            self._reconnect_camera()\n",
    "                            consecutive_failures = 0\n",
    "                        except ConnectionError:\n",
    "                            self.logger.error(\"Failed to reconnect to camera\")\n",
    "                            break\n",
    "\n",
    "                    time.sleep(0.5)\n",
    "                    continue\n",
    "\n",
    "                consecutive_failures = 0\n",
    "\n",
    "                # Detect people\n",
    "                people_count, people_boxes = self.detect_people(frame)\n",
    "                self.draw_bounding_boxes(frame, people_boxes, people_count)\n",
    "                violation_detected = self.draw_professional_overlay(frame, people_count)\n",
    "\n",
    "                if violation_detected:\n",
    "                    current_time = time.time()\n",
    "                    if current_time - self.last_alert_time >= self.CONFIG['alert_cooldown']:\n",
    "                        self.play_sound('violation')\n",
    "                        self.last_alert_time = current_time\n",
    "                        self.logger.warning(f\"Security violation detected: {people_count} people present\")\n",
    "\n",
    "                    if self.CONFIG['recording']['enabled']:\n",
    "                        self.start_violation_recording(frame)\n",
    "                        if self.recording:\n",
    "                            self.violation_writer.write(frame)\n",
    "                else:\n",
    "                    if self.recording:\n",
    "                        self.stop_violation_recording()\n",
    "\n",
    "                cv2.imshow('Bank Vault Security Monitor', frame)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    self.cleanup()\n",
    "                    if self.parent_app:\n",
    "                        self.parent_app.close()  # Close the main application\n",
    "                    sys.exit()  # Exit the entire application\n",
    "                elif key == ord('s'):\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    cv2.imwrite(f'screenshot_{timestamp}.jpg', frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"System error: {e}\")\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources\"\"\"\n",
    "        self.logger.info(\"Shutting down Vault Security System\")\n",
    "        if self.recording:\n",
    "            self.stop_violation_recording()\n",
    "        if hasattr(self, 'cap') and self.cap is not None:\n",
    "            self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    app.setStyle('Fusion')\n",
    "    window = BankSecurityApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 12:05:58,125 - INFO - Enhanced logging system initialized successfully\n",
      "2025-01-30 12:05:58,126 - INFO - Initializing camera connection...\n",
      "2025-01-30 12:06:01,185 - INFO - Camera initialized successfully\n",
      "2025-01-30 12:06:01,363 - ERROR - Error initializing AI models: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:01,364 - ERROR - Failed to launch security system: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:03,410 - INFO - Enhanced logging system initialized successfully\n",
      "2025-01-30 12:06:03,411 - INFO - Initializing camera connection...\n",
      "2025-01-30 12:06:05,468 - INFO - Camera initialized successfully\n",
      "2025-01-30 12:06:05,490 - ERROR - Error initializing AI models: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:05,492 - ERROR - Failed to launch security system: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:10,439 - INFO - Enhanced logging system initialized successfully\n",
      "2025-01-30 12:06:10,440 - INFO - Initializing camera connection...\n",
      "2025-01-30 12:06:12,498 - INFO - Camera initialized successfully\n",
      "2025-01-30 12:06:12,520 - ERROR - Error initializing AI models: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:12,521 - ERROR - Failed to launch security system: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:15,226 - INFO - Enhanced logging system initialized successfully\n",
      "2025-01-30 12:06:15,227 - INFO - Initializing camera connection...\n",
      "2025-01-30 12:06:17,599 - INFO - Camera initialized successfully\n",
      "2025-01-30 12:06:17,622 - ERROR - Error initializing AI models: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:17,623 - ERROR - Failed to launch security system: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:26,083 - INFO - Enhanced logging system initialized successfully\n",
      "2025-01-30 12:06:26,083 - INFO - Initializing camera connection...\n",
      "2025-01-30 12:06:28,156 - INFO - Camera initialized successfully\n",
      "2025-01-30 12:06:28,176 - ERROR - Error initializing AI models: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "2025-01-30 12:06:28,177 - ERROR - Failed to launch security system: [Errno 2] Unable to open file (unable to open file: name = 'models/mask_detection.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import (QApplication, QMainWindow, QPushButton, QLabel, QVBoxLayout, QWidget, QProgressBar, QStackedWidget)\n",
    "from PyQt5.QtGui import QPixmap, QFont, QPalette, QColor, QLinearGradient\n",
    "from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QThread\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from playsound import playsound\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "\n",
    "class LoadingScreen(QWidget):\n",
    "    \"\"\"Professional loading screen with progress bar\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        layout = QVBoxLayout()\n",
    "        self.setLayout(layout)\n",
    "        \n",
    "        # Add loading label\n",
    "        self.loading_label = QLabel(\"Initializing Security Systems...\")\n",
    "        self.loading_label.setFont(QFont('Arial', 14))\n",
    "        self.loading_label.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(self.loading_label)\n",
    "        \n",
    "        # Add progress bar\n",
    "        self.progress = QProgressBar()\n",
    "        self.progress.setStyleSheet(\"\"\"\n",
    "            QProgressBar {\n",
    "                border: 2px solid #00205b;\n",
    "                border-radius: 5px;\n",
    "                text-align: center;\n",
    "            }\n",
    "            QProgressBar::chunk {\n",
    "                background-color: #00205b;\n",
    "            }\n",
    "        \"\"\")\n",
    "        layout.addWidget(self.progress)\n",
    "        \n",
    "        # Initialize progress\n",
    "        self.progress_value = 0\n",
    "        self.timer = QTimer()\n",
    "        self.timer.timeout.connect(self.update_progress)\n",
    "        self.timer.start(30)\n",
    "        \n",
    "    def update_progress(self):\n",
    "        self.progress_value += 1\n",
    "        self.progress.setValue(self.progress_value)\n",
    "        if self.progress_value >= 100:\n",
    "            self.timer.stop()\n",
    "\n",
    "class EnhancedBankSecurityApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"South India Bank - Advanced Security System\")\n",
    "        self.setFixedSize(1000, 700)\n",
    "        \n",
    "        # Create stacked widget for multiple screens\n",
    "        self.stacked_widget = QStackedWidget()\n",
    "        self.setCentralWidget(self.stacked_widget)\n",
    "        \n",
    "        # Create and add loading screen\n",
    "        self.loading_screen = LoadingScreen()\n",
    "        self.stacked_widget.addWidget(self.loading_screen)\n",
    "        \n",
    "        # Create and add main screen\n",
    "        self.main_screen = QWidget()\n",
    "        self.stacked_widget.addWidget(self.main_screen)\n",
    "        \n",
    "        # Setup main screen UI after loading\n",
    "        QTimer.singleShot(3000, self.setup_main_ui)\n",
    "        \n",
    "        # Set modern gradient background\n",
    "        self.setup_gradient_background()\n",
    "\n",
    "    def setup_gradient_background(self):\n",
    "        \"\"\"Create professional gradient background\"\"\"\n",
    "        gradient = QLinearGradient(0, 0, 0, self.height())\n",
    "        gradient.setColorAt(0, QColor('#f5f5f5'))\n",
    "        gradient.setColorAt(1, QColor('#e0e0e0'))\n",
    "        \n",
    "        palette = self.palette()\n",
    "        palette.setBrush(QPalette.Window, gradient)\n",
    "        self.setPalette(palette)\n",
    "\n",
    "    def setup_main_ui(self):\n",
    "        \"\"\"Setup main screen UI with enhanced professional look\"\"\"\n",
    "        layout = QVBoxLayout(self.main_screen)\n",
    "        layout.setSpacing(30)\n",
    "        layout.setContentsMargins(50, 50, 50, 50)\n",
    "        \n",
    "        # Add enhanced bank logo\n",
    "        logo_label = QLabel()\n",
    "        logo_pixmap = QPixmap('assets/bank_logo.png')\n",
    "        scaled_pixmap = logo_pixmap.scaled(400, 400, Qt.KeepAspectRatio, Qt.SmoothTransformation)\n",
    "        logo_label.setPixmap(scaled_pixmap)\n",
    "        logo_label.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(logo_label)\n",
    "        \n",
    "        # Add bank name with enhanced styling\n",
    "        bank_name = QLabel(\"SOUTH INDIA BANK\")\n",
    "        bank_name.setFont(QFont('Arial', 32, QFont.Bold))\n",
    "        bank_name.setStyleSheet(\"\"\"\n",
    "            color: #00205b;\n",
    "            letter-spacing: 2px;\n",
    "            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.1);\n",
    "        \"\"\")\n",
    "        bank_name.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(bank_name)\n",
    "        \n",
    "        # Add enhanced security system tagline\n",
    "        tagline = QLabel(\"Advanced AI-Powered Vault Security System\")\n",
    "        tagline.setFont(QFont('Arial', 18))\n",
    "        tagline.setStyleSheet(\"color: #666666; letter-spacing: 1px;\")\n",
    "        tagline.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(tagline)\n",
    "        \n",
    "        # Add security features list\n",
    "        features = QLabel(\n",
    "            \" Face Detection & Recognition\\n\"\n",
    "            \" Mask Detection\\n\"\n",
    "            \" Multi-Person Tracking\\n\"\n",
    "            \" Real-time Threat Analysis\"\n",
    "        )\n",
    "        features.setFont(QFont('Arial', 12))\n",
    "        features.setStyleSheet(\"color: #444444; margin: 20px;\")\n",
    "        features.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(features)\n",
    "        \n",
    "        # Add enhanced enter button\n",
    "        self.enter_button = QPushButton(\"Launch Security System\")\n",
    "        self.enter_button.setFont(QFont('Arial', 14, QFont.Bold))\n",
    "        self.enter_button.setStyleSheet(\"\"\"\n",
    "            QPushButton {\n",
    "                background-color: #00205b;\n",
    "                color: white;\n",
    "                border: none;\n",
    "                padding: 20px 40px;\n",
    "                border-radius: 10px;\n",
    "                letter-spacing: 1px;\n",
    "            }\n",
    "            QPushButton:hover {\n",
    "                background-color: #003080;\n",
    "                transform: scale(1.05);\n",
    "            }\n",
    "            QPushButton:pressed {\n",
    "                background-color: #001540;\n",
    "            }\n",
    "        \"\"\")\n",
    "        self.enter_button.setFixedWidth(400)\n",
    "        self.enter_button.clicked.connect(self.launch_security_system)\n",
    "        layout.addWidget(self.enter_button, alignment=Qt.AlignCenter)\n",
    "        \n",
    "        # Add enhanced copyright notice\n",
    "        copyright_label = QLabel(\n",
    "            f\" {datetime.now().year} South India Bank. All rights reserved.\\n\"\n",
    "            \"Powered by Advanced AI Security Technology\"\n",
    "        )\n",
    "        copyright_label.setFont(QFont('Arial', 10))\n",
    "        copyright_label.setStyleSheet(\"color: #999999;\")\n",
    "        copyright_label.setAlignment(Qt.AlignCenter)\n",
    "        layout.addWidget(copyright_label)\n",
    "        \n",
    "        # Switch to main screen\n",
    "        self.stacked_widget.setCurrentIndex(1)\n",
    "        \n",
    "        # Initialize vault system as None\n",
    "        self.vault_system = None\n",
    "\n",
    "    def launch_security_system(self):\n",
    "        \"\"\"Launch enhanced security system with error handling\"\"\"\n",
    "        try:\n",
    "            self.hide()\n",
    "            self.vault_system = EnhancedVaultSecuritySystem(parent_app=self)\n",
    "            self.vault_system.run()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to launch security system: {e}\")\n",
    "            self.show()\n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"Enhanced cleanup on application closure\"\"\"\n",
    "        try:\n",
    "            if self.vault_system:\n",
    "                self.vault_system.cleanup()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during cleanup: {e}\")\n",
    "        event.accept()\n",
    "\n",
    "# The EnhancedVaultSecuritySystem class will continue in Part 2...\n",
    "class EnhancedVaultSecuritySystem:\n",
    "    def __init__(self, parent_app=None):\n",
    "        self.parent_app = parent_app\n",
    "        \n",
    "        # Enhanced Configuration\n",
    "        self.CONFIG = {\n",
    "            'required_people': 2,\n",
    "            'confidence_threshold': 0.6,\n",
    "            'alert_cooldown': 3,\n",
    "            'log_directory': 'vault_logs',\n",
    "            'alert_sounds': {\n",
    "                'violation': 'assets/alarm.wav',\n",
    "                'access_granted': 'assets/access_granted.wav',\n",
    "                'mask_violation': 'assets/mask_alert.wav',\n",
    "                'face_covered': 'assets/face_alert.wav'\n",
    "            },\n",
    "            'recording': {\n",
    "                'enabled': True,\n",
    "                'violation_clip_duration': 10,\n",
    "                'output_directory': 'violation_clips',\n",
    "                'quality': 'high'\n",
    "            },\n",
    "            'camera': {\n",
    "                'rtsp_url': 'rtsp://admin:OUESEH@192.168.29.112:554/h264/ch1/main/av_stream',\n",
    "                'reconnect_attempts': 3,\n",
    "                'reconnect_delay': 2,\n",
    "                'buffer_size': 1\n",
    "            },\n",
    "            'ai_models': {\n",
    "                'face_detection_confidence': 0.7,\n",
    "                'mask_detection_confidence': 0.8,\n",
    "                'person_tracking_threshold': 0.5\n",
    "            },\n",
    "            'ui': {\n",
    "                'show_metrics': True,\n",
    "                'show_alerts': True,\n",
    "                'show_timestamps': True\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Initialize components\n",
    "        self._setup_logging()\n",
    "        self._initialize_camera()\n",
    "        self._initialize_ai_models()\n",
    "        self._create_directories()\n",
    "        self._load_ui_elements()\n",
    "        \n",
    "        # Enhanced state management\n",
    "        self.system_state = {\n",
    "            'alert_active': False,\n",
    "            'last_alert_time': 0,\n",
    "            'recording_active': False,\n",
    "            'face_detected': False,\n",
    "            'mask_violation': False,\n",
    "            'suspicious_activity': False,\n",
    "            'system_healthy': True\n",
    "        }\n",
    "\n",
    "    def _initialize_ai_models(self):\n",
    "        \"\"\"Initialize all AI models for enhanced detection\"\"\"\n",
    "        try:\n",
    "            # Initialize YOLO model for person detection\n",
    "            self.person_model = YOLO('yolov8n.pt')\n",
    "            \n",
    "            # Initialize MediaPipe for face detection\n",
    "            self.mp_face_detection = mp.solutions.face_detection\n",
    "            self.face_detection = self.mp_face_detection.FaceDetection(\n",
    "                min_detection_confidence=self.CONFIG['ai_models']['face_detection_confidence']\n",
    "            )\n",
    "            \n",
    "            # Initialize mask detection model\n",
    "            self.mask_model = tf.keras.models.load_model('models/mask_detection.h5')\n",
    "            \n",
    "            self.logger.info(\"AI models initialized successfully\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error initializing AI models: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configure enhanced logging system\"\"\"\n",
    "        try:\n",
    "            log_dir = Path(self.CONFIG['log_directory'])\n",
    "            log_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            log_file = log_dir / f'vault_security_{datetime.now().strftime(\"%Y%m%d\")}.log'\n",
    "            \n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[\n",
    "                    logging.FileHandler(str(log_file)),\n",
    "                    logging.StreamHandler()\n",
    "                ]\n",
    "            )\n",
    "            self.logger = logging.getLogger('EnhancedVaultSecurity')\n",
    "            self.logger.info('Enhanced logging system initialized successfully')\n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up logging: {e}\")\n",
    "            logging.basicConfig(\n",
    "                level=logging.INFO,\n",
    "                format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                handlers=[logging.StreamHandler()]\n",
    "            )\n",
    "            self.logger = logging.getLogger('EnhancedVaultSecurity')\n",
    "\n",
    "    def _initialize_camera(self):\n",
    "        \"\"\"Initialize camera with enhanced error handling\"\"\"\n",
    "        self.logger.info(\"Initializing camera connection...\")\n",
    "        \n",
    "        for attempt in range(self.CONFIG['camera']['reconnect_attempts']):\n",
    "            try:\n",
    "                self.cap = cv2.VideoCapture(self.CONFIG['camera']['rtsp_url'])\n",
    "                \n",
    "                if self.cap.isOpened():\n",
    "                    # Set optimal camera parameters\n",
    "                    self.cap.set(cv2.CAP_PROP_BUFFERSIZE, \n",
    "                               self.CONFIG['camera']['buffer_size'])\n",
    "                    self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "                    self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "                    self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "                    \n",
    "                    self.logger.info(\"Camera initialized successfully\")\n",
    "                    return\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Camera initialization attempt {attempt + 1} failed: {e}\")\n",
    "                time.sleep(self.CONFIG['camera']['reconnect_delay'])\n",
    "        \n",
    "        raise ConnectionError(\"Failed to initialize camera after all attempts\")\n",
    "    \n",
    "def detect_face_and_mask(self, frame):\n",
    "        \"\"\"Enhanced face and mask detection\"\"\"\n",
    "        try:\n",
    "            # Convert to RGB for MediaPipe\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Detect faces\n",
    "            face_results = self.face_detection.process(rgb_frame)\n",
    "            faces_detected = []\n",
    "            mask_violations = []\n",
    "            \n",
    "            if face_results.detections:\n",
    "                for detection in face_results.detections:\n",
    "                    bbox = detection.location_data.relative_bounding_box\n",
    "                    h, w, _ = frame.shape\n",
    "                    \n",
    "                    # Convert relative coordinates to absolute\n",
    "                    x, y = int(bbox.xmin * w), int(bbox.ymin * h)\n",
    "                    width, height = int(bbox.width * w), int(bbox.height * h)\n",
    "                    \n",
    "                    # Extract face region for mask detection\n",
    "                    face_region = frame[y:y+height, x:x+width]\n",
    "                    if face_region.size > 0:\n",
    "                        # Prepare for mask detection\n",
    "                        face_region = cv2.resize(face_region, (128, 128))\n",
    "                        face_region = face_region / 255.0\n",
    "                        face_region = np.expand_dims(face_region, axis=0)\n",
    "                        \n",
    "                        # Detect mask\n",
    "                        mask_pred = self.mask_model.predict(face_region, verbose=0)\n",
    "                        wearing_mask = mask_pred[0][0] > self.CONFIG['ai_models']['mask_detection_confidence']\n",
    "                        \n",
    "                        faces_detected.append((x, y, width, height))\n",
    "                        if not wearing_mask:\n",
    "                            mask_violations.append((x, y, width, height))\n",
    "            \n",
    "            return faces_detected, mask_violations\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error in face and mask detection: {e}\")\n",
    "            return [], []\n",
    "\n",
    "def detect_people(self, frame):\n",
    "    \"\"\"Enhanced people detection with tracking\"\"\"\n",
    "    try:\n",
    "        results = self.person_model(frame, conf=self.CONFIG['ai_models']['person_tracking_threshold'])\n",
    "        \n",
    "        people_boxes = []\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                if box.cls == 0:  # Person class\n",
    "                    people_boxes.append(box)\n",
    "        \n",
    "        return len(people_boxes), people_boxes\n",
    "    except Exception as e:\n",
    "        self.logger.error(f\"Error in people detection: {e}\")\n",
    "        return 0, []\n",
    "\n",
    "def analyze_security_threat(self, people_count, mask_violations, faces):\n",
    "    \"\"\"Analyze overall security threat level\"\"\"\n",
    "    threat_level = 0\n",
    "    threat_reasons = []\n",
    "    \n",
    "    # Check number of people\n",
    "    if people_count != self.CONFIG['required_people']:\n",
    "        threat_level += 3\n",
    "        threat_reasons.append(f\"Incorrect number of people: {people_count}\")\n",
    "    \n",
    "    # Check mask violations\n",
    "    if mask_violations:\n",
    "        threat_level += 2\n",
    "        threat_reasons.append(f\"Mask violations detected: {len(mask_violations)}\")\n",
    "    \n",
    "    # Check face concealment\n",
    "    if people_count > len(faces):\n",
    "        threat_level += 2\n",
    "        threat_reasons.append(\"Some faces not visible\")\n",
    "    \n",
    "    return {\n",
    "        'level': min(threat_level, 5),  # Scale 0-5\n",
    "        'reasons': threat_reasons\n",
    "    }\n",
    "\n",
    "def draw_detection_overlays(self, frame, people_boxes, faces, mask_violations):\n",
    "    \"\"\"Draw all detection overlays\"\"\"\n",
    "    # Draw person boxes\n",
    "    for box in people_boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Add confidence score\n",
    "        conf = float(box.conf[0])\n",
    "        cv2.putText(frame, f\"{conf:.2f}\", (x1, y1-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Draw face boxes\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "    \n",
    "    # Draw mask violations\n",
    "    for (x, y, w, h) in mask_violations:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"NO MASK\", (x, y-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "def draw_enhanced_ui(self, frame, people_count, faces, mask_violations, threat_analysis):\n",
    "        \"\"\"Draw enhanced UI with security metrics\"\"\"\n",
    "        # Add top bar background\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (frame.shape[1], 140), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "\n",
    "        # Status section\n",
    "        status_text = \"VAULT SECURITY STATUS:\"\n",
    "        if threat_analysis['level'] == 0:\n",
    "            status = \"ACCESS GRANTED\"\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            status = \"ACCESS DENIED\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        cv2.putText(frame, status_text, (50, 40),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, (200, 200, 200), 2)\n",
    "        cv2.putText(frame, status, (50, 80),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 1, color, 2)\n",
    "\n",
    "        # Metrics section\n",
    "        metrics_x = frame.shape[1] - 400\n",
    "        cv2.putText(frame, f\"People: {people_count}/{self.CONFIG['required_people']}\", \n",
    "                   (metrics_x, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(frame, f\"Faces Detected: {len(faces)}\", \n",
    "                   (metrics_x, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "        cv2.putText(frame, f\"Mask Violations: {len(mask_violations)}\", \n",
    "                   (metrics_x, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "        # Threat level indicator\n",
    "        threat_x = frame.shape[1] // 2 - 100\n",
    "        cv2.putText(frame, f\"Threat Level: {threat_analysis['level']}/5\", \n",
    "                   (threat_x, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "        # Time and recording status\n",
    "        if self.system_state['recording_active']:\n",
    "            cv2.circle(frame, (frame.shape[1]-50, 30), 10, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, \"REC\", (frame.shape[1]-100, 35),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "        cv2.putText(frame, current_time, (frame.shape[1]-150, 130),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200, 200, 200), 2)\n",
    "\n",
    "def run(self):\n",
    "        \"\"\"Enhanced main monitoring loop\"\"\"\n",
    "        self.logger.info(\"Starting Enhanced Vault Security System\")\n",
    "        consecutive_failures = 0\n",
    "        max_failures = 5\n",
    "        fps_counter = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = self.cap.read()\n",
    "                \n",
    "                if not ret:\n",
    "                    consecutive_failures += 1\n",
    "                    self.logger.warning(f\"Frame read failure {consecutive_failures}/{max_failures}\")\n",
    "                    \n",
    "                    if consecutive_failures >= max_failures:\n",
    "                        self.logger.error(\"Multiple frame read failures, attempting to reconnect...\")\n",
    "                        try:\n",
    "                            self._initialize_camera()\n",
    "                            consecutive_failures = 0\n",
    "                        except ConnectionError:\n",
    "                            self.logger.error(\"Failed to reconnect to camera\")\n",
    "                            break\n",
    "                    \n",
    "                    time.sleep(0.5)\n",
    "                    continue\n",
    "\n",
    "                consecutive_failures = 0\n",
    "\n",
    "                # Calculate FPS\n",
    "                fps_counter += 1\n",
    "                if (time.time() - fps_start_time) > 1:\n",
    "                    self.current_fps = fps_counter\n",
    "                    fps_counter = 0\n",
    "                    fps_start_time = time.time()\n",
    "\n",
    "                # Run all detections\n",
    "                people_count, people_boxes = self.detect_people(frame)\n",
    "                faces, mask_violations = self.detect_face_and_mask(frame)\n",
    "                \n",
    "                # Analyze security threat\n",
    "                threat_analysis = self.analyze_security_threat(\n",
    "                    people_count, mask_violations, faces\n",
    "                )\n",
    "\n",
    "                # Draw all visual elements\n",
    "                self.draw_detection_overlays(frame, people_boxes, faces, mask_violations)\n",
    "                self.draw_enhanced_ui(frame, people_count, faces, mask_violations, threat_analysis)\n",
    "\n",
    "                # Handle alerts and recordings\n",
    "                current_time = time.time()\n",
    "                if threat_analysis['level'] > 0:\n",
    "                    if current_time - self.system_state['last_alert_time'] >= self.CONFIG['alert_cooldown']:\n",
    "                        # Play appropriate alert sounds\n",
    "                        if mask_violations:\n",
    "                            self.play_sound('mask_violation')\n",
    "                        else:\n",
    "                            self.play_sound('violation')\n",
    "                        self.system_state['last_alert_time'] = current_time\n",
    "                        self.logger.warning(f\"Security threat detected: {threat_analysis['reasons']}\")\n",
    "\n",
    "                    # Handle recording\n",
    "                    if self.CONFIG['recording']['enabled']:\n",
    "                        if not self.system_state['recording_active']:\n",
    "                            self.start_violation_recording(frame)\n",
    "                        elif self.recording_writer:\n",
    "                            self.recording_writer.write(frame)\n",
    "                else:\n",
    "                    if self.system_state['recording_active']:\n",
    "                        self.stop_violation_recording()\n",
    "\n",
    "                # Add FPS counter\n",
    "                cv2.putText(frame, f\"FPS: {self.current_fps}\", (10, frame.shape[0] - 20),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                # Display frame\n",
    "                cv2.imshow('Enhanced Bank Vault Security Monitor', frame)\n",
    "\n",
    "                # Handle key presses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    self.logger.info(\"User requested shutdown\")\n",
    "                    self.cleanup()\n",
    "                    if self.parent_app:\n",
    "                        self.parent_app.close()\n",
    "                    sys.exit()\n",
    "                elif key == ord('s'):\n",
    "                    # Take screenshot\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    screenshot_path = f'screenshots/security_snapshot_{timestamp}.jpg'\n",
    "                    cv2.imwrite(screenshot_path, frame)\n",
    "                    self.logger.info(f\"Screenshot saved: {screenshot_path}\")\n",
    "                elif key == ord('r'):\n",
    "                    # Toggle recording\n",
    "                    if not self.system_state['recording_active']:\n",
    "                        self.start_violation_recording(frame)\n",
    "                    else:\n",
    "                        self.stop_violation_recording()\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Critical system error: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "        def start_violation_recording(self, frame):\n",
    "            \"\"\"Start recording with enhanced quality settings\"\"\"\n",
    "            if not self.system_state['recording_active']:\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                output_path = os.path.join(\n",
    "                    self.CONFIG['recording']['output_directory'],\n",
    "                    f'security_violation_{timestamp}.mp4'\n",
    "                )\n",
    "                \n",
    "                # Use H.264 codec with high quality settings\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
    "                self.recording_writer = cv2.VideoWriter(\n",
    "                    output_path, fourcc, 30.0,\n",
    "                    (frame.shape[1], frame.shape[0])\n",
    "                )\n",
    "                \n",
    "                self.system_state['recording_active'] = True\n",
    "                self.logger.info(f\"Started recording: {output_path}\")\n",
    "\n",
    "        def stop_violation_recording(self):\n",
    "            \"\"\"Stop recording and cleanup\"\"\"\n",
    "            if self.system_state['recording_active']:\n",
    "                if hasattr(self, 'recording_writer') and self.recording_writer:\n",
    "                    self.recording_writer.release()\n",
    "                    self.recording_writer = None\n",
    "                self.system_state['recording_active'] = False\n",
    "                self.logger.info(\"Stopped recording\")\n",
    "\n",
    "        def cleanup(self):\n",
    "            \"\"\"Enhanced cleanup with proper resource management\"\"\"\n",
    "            self.logger.info(\"Performing system cleanup...\")\n",
    "            try:\n",
    "                if self.system_state['recording_active']:\n",
    "                    self.stop_violation_recording()\n",
    "                \n",
    "                if hasattr(self, 'cap') and self.cap is not None:\n",
    "                    self.cap.release()\n",
    "                \n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                # Release AI models\n",
    "                if hasattr(self, 'face_detection'):\n",
    "                    self.face_detection.close()\n",
    "                \n",
    "                self.logger.info(\"Cleanup completed successfully\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error during cleanup: {e}\")\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    app.setStyle('Fusion')\n",
    "    window = EnhancedBankSecurityApp()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x640 21 panels, 50.3ms\n",
      "Speed: 3.4ms preprocess, 50.3ms inference, 61.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 6.9ms\n",
      "Speed: 9.6ms preprocess, 6.9ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 3.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 14.1ms\n",
      "Speed: 0.0ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 8.5ms\n",
      "Speed: 2.0ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.7ms\n",
      "Speed: 0.0ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 27 panels, 7.2ms\n",
      "Speed: 0.0ms preprocess, 7.2ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 28 panels, 11.1ms\n",
      "Speed: 0.0ms preprocess, 11.1ms inference, 3.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 27 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.4ms\n",
      "Speed: 1.0ms preprocess, 10.4ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 5.7ms\n",
      "Speed: 1.3ms preprocess, 5.7ms inference, 8.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 0.0ms\n",
      "Speed: 1.3ms preprocess, 0.0ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 41 panels, 3.7ms\n",
      "Speed: 1.0ms preprocess, 3.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 16.2ms\n",
      "Speed: 0.0ms preprocess, 16.2ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 30 panels, 3.0ms\n",
      "Speed: 0.9ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 5.7ms\n",
      "Speed: 0.0ms preprocess, 5.7ms inference, 4.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 9.2ms\n",
      "Speed: 0.0ms preprocess, 9.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 9.3ms\n",
      "Speed: 0.0ms preprocess, 9.3ms inference, 4.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 6.7ms\n",
      "Speed: 2.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 0.0ms\n",
      "Speed: 7.4ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 38 panels, 9.4ms\n",
      "Speed: 0.0ms preprocess, 9.4ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 32 panels, 11.5ms\n",
      "Speed: 1.0ms preprocess, 11.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 9.9ms\n",
      "Speed: 0.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.0ms\n",
      "Speed: 2.5ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 7.6ms\n",
      "Speed: 0.0ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 27 panels, 6.3ms\n",
      "Speed: 1.0ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 33 panels, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 6.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 6.0ms\n",
      "Speed: 1.6ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 28 panels, 6.7ms\n",
      "Speed: 3.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 33 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 30 panels, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 6.1ms\n",
      "Speed: 0.0ms preprocess, 6.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 40 panels, 16.6ms\n",
      "Speed: 0.0ms preprocess, 16.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 31 panels, 6.5ms\n",
      "Speed: 0.0ms preprocess, 6.5ms inference, 3.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 38 panels, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 28 panels, 6.4ms\n",
      "Speed: 2.5ms preprocess, 6.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 30 panels, 5.8ms\n",
      "Speed: 4.1ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 39 panels, 5.1ms\n",
      "Speed: 0.3ms preprocess, 5.1ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 37 panels, 9.5ms\n",
      "Speed: 0.0ms preprocess, 9.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 32 panels, 9.8ms\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 41 panels, 9.6ms\n",
      "Speed: 0.0ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 2.7ms\n",
      "Speed: 2.0ms preprocess, 2.7ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 37 panels, 5.1ms\n",
      "Speed: 5.1ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 4.5ms\n",
      "Speed: 0.6ms preprocess, 4.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 5.2ms\n",
      "Speed: 0.0ms preprocess, 5.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 14.9ms\n",
      "Speed: 0.0ms preprocess, 14.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 30 panels, 4.0ms\n",
      "Speed: 0.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 4.1ms\n",
      "Speed: 0.0ms preprocess, 4.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 10.3ms\n",
      "Speed: 0.0ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 27 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 4.1ms\n",
      "Speed: 0.0ms preprocess, 4.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 4.6ms\n",
      "Speed: 9.9ms preprocess, 4.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 28 panels, 5.0ms\n",
      "Speed: 5.1ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 4.1ms\n",
      "Speed: 0.0ms preprocess, 4.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.1ms\n",
      "Speed: 9.9ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 31 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 5.0ms\n",
      "Speed: 4.6ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 5.1ms\n",
      "Speed: 5.0ms preprocess, 5.1ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 0.0ms\n",
      "Speed: 9.3ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 0.0ms\n",
      "Speed: 9.4ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 6.0ms\n",
      "Speed: 10.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 4.6ms\n",
      "Speed: 0.0ms preprocess, 4.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 31 panels, 0.0ms\n",
      "Speed: 4.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 5.0ms\n",
      "Speed: 0.1ms preprocess, 5.0ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 33 panels, 14.8ms\n",
      "Speed: 0.0ms preprocess, 14.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 32 panels, 0.0ms\n",
      "Speed: 4.5ms preprocess, 0.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 6.2ms\n",
      "Speed: 5.0ms preprocess, 6.2ms inference, 3.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 5.0ms\n",
      "Speed: 5.0ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 28 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 5.1ms\n",
      "Speed: 0.0ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 0.0ms\n",
      "Speed: 4.6ms preprocess, 0.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 10.0ms\n",
      "Speed: 4.5ms preprocess, 10.0ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 7.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 0.0ms\n",
      "Speed: 5.1ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 10.4ms\n",
      "Speed: 0.0ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 0.0ms\n",
      "Speed: 4.5ms preprocess, 0.0ms inference, 10.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 10.0ms\n",
      "Speed: 10.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.0ms\n",
      "Speed: 10.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 10.1ms\n",
      "Speed: 5.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 9.9ms\n",
      "Speed: 4.6ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 9.5ms\n",
      "Speed: 9.9ms preprocess, 9.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 9.6ms\n",
      "Speed: 9.8ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 10.2ms\n",
      "Speed: 9.5ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 15.2ms\n",
      "Speed: 0.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 10.1ms\n",
      "Speed: 9.9ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.2ms\n",
      "Speed: 9.5ms preprocess, 10.2ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.0ms\n",
      "Speed: 2.6ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 10.2ms\n",
      "Speed: 4.8ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 14.9ms\n",
      "Speed: 0.0ms preprocess, 14.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.6ms\n",
      "Speed: 4.6ms preprocess, 10.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 19.6ms\n",
      "Speed: 0.0ms preprocess, 19.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 9.7ms\n",
      "Speed: 10.1ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 9.9ms\n",
      "Speed: 9.7ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 9.7ms\n",
      "Speed: 5.0ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 9.7ms\n",
      "Speed: 5.1ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 9.6ms\n",
      "Speed: 0.2ms preprocess, 9.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.1ms\n",
      "Speed: 10.3ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.3ms\n",
      "Speed: 9.5ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.3ms\n",
      "Speed: 0.0ms preprocess, 10.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.3ms\n",
      "Speed: 8.6ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.2ms\n",
      "Speed: 5.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 20.2ms\n",
      "Speed: 0.0ms preprocess, 20.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 30.5ms\n",
      "Speed: 9.6ms preprocess, 30.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 20.3ms\n",
      "Speed: 9.6ms preprocess, 20.3ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 29.7ms\n",
      "Speed: 9.8ms preprocess, 29.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 20.0ms\n",
      "Speed: 10.0ms preprocess, 20.0ms inference, 10.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 30.2ms\n",
      "Speed: 0.1ms preprocess, 30.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 19.9ms\n",
      "Speed: 9.7ms preprocess, 19.9ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 19.9ms\n",
      "Speed: 10.1ms preprocess, 19.9ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 20.0ms\n",
      "Speed: 10.3ms preprocess, 20.0ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 24.8ms\n",
      "Speed: 5.0ms preprocess, 24.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 25.1ms\n",
      "Speed: 9.8ms preprocess, 25.1ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 19.0ms\n",
      "Speed: 3.6ms preprocess, 19.0ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 19.7ms\n",
      "Speed: 10.0ms preprocess, 19.7ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 24.7ms\n",
      "Speed: 9.6ms preprocess, 24.7ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 20.2ms\n",
      "Speed: 9.7ms preprocess, 20.2ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 20.1ms\n",
      "Speed: 9.7ms preprocess, 20.1ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 20.4ms\n",
      "Speed: 4.6ms preprocess, 20.4ms inference, 9.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 20.0ms\n",
      "Speed: 4.6ms preprocess, 20.0ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 24.7ms\n",
      "Speed: 9.9ms preprocess, 24.7ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 20.1ms\n",
      "Speed: 5.1ms preprocess, 20.1ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 24.6ms\n",
      "Speed: 9.8ms preprocess, 24.6ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 20.1ms\n",
      "Speed: 10.0ms preprocess, 20.1ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 19.7ms\n",
      "Speed: 10.1ms preprocess, 19.7ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 10.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 25.3ms\n",
      "Speed: 0.0ms preprocess, 25.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 20.9ms\n",
      "Speed: 4.6ms preprocess, 20.9ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 20.2ms\n",
      "Speed: 5.0ms preprocess, 20.2ms inference, 9.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 4.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 20.3ms\n",
      "Speed: 5.0ms preprocess, 20.3ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 30.1ms\n",
      "Speed: 0.0ms preprocess, 30.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 25.2ms\n",
      "Speed: 4.6ms preprocess, 25.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.6ms\n",
      "Speed: 9.8ms preprocess, 0.6ms inference, 9.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 0.0ms\n",
      "Speed: 9.8ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 0.0ms\n",
      "Speed: 4.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 9.6ms\n",
      "Speed: 0.0ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 0.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 6.6ms\n",
      "Speed: 1.0ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.0ms\n",
      "Speed: 10.1ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 0.0ms\n",
      "Speed: 5.0ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 5.0ms\n",
      "Speed: 9.8ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 0.0ms\n",
      "Speed: 5.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 5.0ms\n",
      "Speed: 5.0ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 2.6ms\n",
      "Speed: 5.0ms preprocess, 2.6ms inference, 7.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 9.9ms\n",
      "Speed: 0.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 panels, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.0ms\n",
      "Speed: 10.2ms preprocess, 0.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 8 panels, 5.0ms\n",
      "Speed: 5.2ms preprocess, 5.0ms inference, 4.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 0.0ms\n",
      "Speed: 9.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 5.0ms\n",
      "Speed: 5.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 3.6ms\n",
      "Speed: 5.0ms preprocess, 3.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 0.0ms\n",
      "Speed: 10.2ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 9.8ms\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 4.0ms\n",
      "Speed: 4.7ms preprocess, 4.0ms inference, 6.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 10.2ms\n",
      "Speed: 4.6ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 9.8ms\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 9.8ms\n",
      "Speed: 5.1ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 20.1ms\n",
      "Speed: 0.0ms preprocess, 20.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 10.0ms\n",
      "Speed: 6.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 10.1ms\n",
      "Speed: 5.1ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 10.0ms\n",
      "Speed: 4.6ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 10.3ms\n",
      "Speed: 0.0ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 10.4ms\n",
      "Speed: 9.7ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 15.2ms\n",
      "Speed: 0.0ms preprocess, 15.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 9.7ms\n",
      "Speed: 5.1ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.5ms\n",
      "Speed: 0.0ms preprocess, 10.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 10.2ms\n",
      "Speed: 4.5ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 9.7ms\n",
      "Speed: 9.9ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 10.1ms\n",
      "Speed: 5.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 14.9ms\n",
      "Speed: 0.0ms preprocess, 14.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.0ms\n",
      "Speed: 9.9ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 27 panels, 10.1ms\n",
      "Speed: 4.5ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 10.1ms\n",
      "Speed: 1.7ms preprocess, 10.1ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 10.1ms\n",
      "Speed: 4.6ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 panels, 9.7ms\n",
      "Speed: 9.6ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 10.2ms\n",
      "Speed: 4.6ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 30.1ms\n",
      "Speed: 0.0ms preprocess, 30.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 30.2ms\n",
      "Speed: 4.6ms preprocess, 30.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 30.3ms\n",
      "Speed: 9.6ms preprocess, 30.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 20.1ms\n",
      "Speed: 5.0ms preprocess, 20.1ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 30.2ms\n",
      "Speed: 0.0ms preprocess, 30.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 24.7ms\n",
      "Speed: 5.1ms preprocess, 24.7ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 29 panels, 19.5ms\n",
      "Speed: 10.2ms preprocess, 19.5ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 31.0ms\n",
      "Speed: 0.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 30.3ms\n",
      "Speed: 0.0ms preprocess, 30.3ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 25.0ms\n",
      "Speed: 9.8ms preprocess, 25.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 19.8ms\n",
      "Speed: 10.0ms preprocess, 19.8ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 9.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 26.0ms\n",
      "Speed: 5.1ms preprocess, 26.0ms inference, 4.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 29.7ms\n",
      "Speed: 0.0ms preprocess, 29.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 29.9ms\n",
      "Speed: 0.0ms preprocess, 29.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 24.7ms\n",
      "Speed: 5.0ms preprocess, 24.7ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 29.8ms\n",
      "Speed: 0.0ms preprocess, 29.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 25.4ms\n",
      "Speed: 4.6ms preprocess, 25.4ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 20.0ms\n",
      "Speed: 9.9ms preprocess, 20.0ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 20.0ms\n",
      "Speed: 9.8ms preprocess, 20.0ms inference, 9.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 20.3ms\n",
      "Speed: 2.6ms preprocess, 20.3ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 25.3ms\n",
      "Speed: 5.0ms preprocess, 25.3ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 25.2ms\n",
      "Speed: 9.6ms preprocess, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 24.5ms\n",
      "Speed: 2.2ms preprocess, 24.5ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 20.2ms\n",
      "Speed: 9.5ms preprocess, 20.2ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 20.1ms\n",
      "Speed: 5.1ms preprocess, 20.1ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 20.1ms\n",
      "Speed: 5.1ms preprocess, 20.1ms inference, 9.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 25.2ms\n",
      "Speed: 0.0ms preprocess, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 19.8ms\n",
      "Speed: 0.0ms preprocess, 19.8ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 20.3ms\n",
      "Speed: 5.0ms preprocess, 20.3ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 24.6ms\n",
      "Speed: 3.1ms preprocess, 24.6ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 9.6ms\n",
      "Speed: 0.0ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 0.0ms\n",
      "Speed: 10.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 5.0ms\n",
      "Speed: 2.6ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 5.0ms\n",
      "Speed: 5.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 5.0ms\n",
      "Speed: 9.6ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 0.0ms\n",
      "Speed: 5.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 10.1ms\n",
      "Speed: 2.6ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 0.0ms\n",
      "Speed: 9.8ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 0.0ms\n",
      "Speed: 4.6ms preprocess, 0.0ms inference, 9.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 0.0ms\n",
      "Speed: 5.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 5.0ms\n",
      "Speed: 5.1ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 10.5ms\n",
      "Speed: 9.7ms preprocess, 10.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 7.5ms\n",
      "Speed: 5.0ms preprocess, 7.5ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 5.0ms\n",
      "Speed: 0.0ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 5.0ms\n",
      "Speed: 5.1ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 5.0ms\n",
      "Speed: 9.5ms preprocess, 5.0ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 9.8ms\n",
      "Speed: 5.0ms preprocess, 9.8ms inference, 0.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.0ms\n",
      "Speed: 5.1ms preprocess, 0.0ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 0.0ms\n",
      "Speed: 9.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 0.0ms\n",
      "Speed: 5.1ms preprocess, 0.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.0ms\n",
      "Speed: 9.8ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 0.0ms\n",
      "Speed: 9.5ms preprocess, 0.0ms inference, 10.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 15.0ms\n",
      "Speed: 0.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 27 panels, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 28.9ms\n",
      "Speed: 4.6ms preprocess, 28.9ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 19.6ms\n",
      "Speed: 10.0ms preprocess, 19.6ms inference, 9.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 25.2ms\n",
      "Speed: 9.5ms preprocess, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 25.2ms\n",
      "Speed: 10.0ms preprocess, 25.2ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 20.0ms\n",
      "Speed: 5.2ms preprocess, 20.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 25.2ms\n",
      "Speed: 5.0ms preprocess, 25.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 29.8ms\n",
      "Speed: 0.0ms preprocess, 29.8ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 20.0ms\n",
      "Speed: 4.6ms preprocess, 20.0ms inference, 10.3ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 20.4ms\n",
      "Speed: 9.7ms preprocess, 20.4ms inference, 9.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 24.9ms\n",
      "Speed: 0.5ms preprocess, 24.9ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 29.8ms\n",
      "Speed: 0.0ms preprocess, 29.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 25.2ms\n",
      "Speed: 9.5ms preprocess, 25.2ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 20.3ms\n",
      "Speed: 9.4ms preprocess, 20.3ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 24.7ms\n",
      "Speed: 9.8ms preprocess, 24.7ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 20.0ms\n",
      "Speed: 10.2ms preprocess, 20.0ms inference, 10.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 19.8ms\n",
      "Speed: 5.0ms preprocess, 19.8ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 panels, 24.9ms\n",
      "Speed: 0.0ms preprocess, 24.9ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 24.7ms\n",
      "Speed: 10.2ms preprocess, 24.7ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 20.0ms\n",
      "Speed: 10.0ms preprocess, 20.0ms inference, 9.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 20.3ms\n",
      "Speed: 0.0ms preprocess, 20.3ms inference, 9.7ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 24.7ms\n",
      "Speed: 5.1ms preprocess, 24.7ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 20.0ms\n",
      "Speed: 5.3ms preprocess, 20.0ms inference, 10.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 18.9ms\n",
      "Speed: 2.8ms preprocess, 18.9ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 24.7ms\n",
      "Speed: 5.1ms preprocess, 24.7ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 24.7ms\n",
      "Speed: 5.2ms preprocess, 24.7ms inference, 5.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 5.0ms\n",
      "Speed: 10.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 0.0ms\n",
      "Speed: 4.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 0.5ms\n",
      "Speed: 4.6ms preprocess, 0.5ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 0.0ms\n",
      "Speed: 9.9ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 0.0ms\n",
      "Speed: 9.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.0ms\n",
      "Speed: 0.0ms preprocess, 0.0ms inference, 9.6ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 panels, 0.0ms\n",
      "Speed: 4.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 0.0ms\n",
      "Speed: 4.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 10.2ms\n",
      "Speed: 4.5ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 0.0ms\n",
      "Speed: 4.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 panels, 0.0ms\n",
      "Speed: 4.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 0.0ms\n",
      "Speed: 9.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 25 panels, 0.0ms\n",
      "Speed: 9.7ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 10 panels, 10.1ms\n",
      "Speed: 0.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 26 panels, 0.0ms\n",
      "Speed: 4.5ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 9.9ms\n",
      "Speed: 0.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 0.0ms\n",
      "Speed: 9.8ms preprocess, 0.0ms inference, 10.2ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 0.0ms\n",
      "Speed: 5.0ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.0ms\n",
      "Speed: 4.6ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.3ms\n",
      "Speed: 5.1ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 5.0ms\n",
      "Speed: 10.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 10.2ms\n",
      "Speed: 0.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 0.0ms\n",
      "Speed: 5.0ms preprocess, 0.0ms inference, 9.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 0.0ms\n",
      "Speed: 1.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 18 panels, 0.0ms\n",
      "Speed: 9.8ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 5.0ms\n",
      "Speed: 5.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 0.0ms\n",
      "Speed: 10.1ms preprocess, 0.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 9.6ms\n",
      "Speed: 5.1ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 9.9ms\n",
      "Speed: 5.1ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 10.2ms\n",
      "Speed: 5.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 9.7ms\n",
      "Speed: 5.0ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 panels, 10.3ms\n",
      "Speed: 8.1ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 panels, 10.2ms\n",
      "Speed: 9.6ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.0ms\n",
      "Speed: 10.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 24 panels, 10.1ms\n",
      "Speed: 10.0ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 16 panels, 10.0ms\n",
      "Speed: 5.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 11 panels, 15.8ms\n",
      "Speed: 0.0ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.4ms\n",
      "Speed: 9.7ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 panels, 10.2ms\n",
      "Speed: 10.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.4ms\n",
      "Speed: 4.6ms preprocess, 10.4ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 7 panels, 10.1ms\n",
      "Speed: 4.7ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 9.6ms\n",
      "Speed: 5.1ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 19 panels, 10.3ms\n",
      "Speed: 0.0ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 10.2ms\n",
      "Speed: 9.8ms preprocess, 10.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 12 panels, 10.1ms\n",
      "Speed: 6.5ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 10.1ms\n",
      "Speed: 4.7ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 panels, 10.2ms\n",
      "Speed: 4.6ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 15 panels, 10.4ms\n",
      "Speed: 9.8ms preprocess, 10.4ms inference, 4.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 9 panels, 9.7ms\n",
      "Speed: 10.3ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 10.2ms\n",
      "Speed: 5.0ms preprocess, 10.2ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 13 panels, 10.1ms\n",
      "Speed: 5.2ms preprocess, 10.1ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 10.3ms\n",
      "Speed: 5.0ms preprocess, 10.3ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 14 panels, 9.8ms\n",
      "Speed: 2.1ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 10.2ms\n",
      "Speed: 4.6ms preprocess, 10.2ms inference, 4.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 9.8ms\n",
      "Speed: 5.0ms preprocess, 9.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 23 panels, 24.9ms\n",
      "Speed: 0.0ms preprocess, 24.9ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 21 panels, 29.8ms\n",
      "Speed: 5.5ms preprocess, 29.8ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 17 panels, 30.2ms\n",
      "Speed: 5.0ms preprocess, 30.2ms inference, 5.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 22 panels, 30.0ms\n",
      "Speed: 9.8ms preprocess, 30.0ms inference, 0.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "\n",
      "0: 512x640 20 panels, 30.0ms\n",
      "Speed: 0.0ms preprocess, 30.0ms inference, 5.1ms postprocess per image at shape (1, 3, 512, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "class SRTParser:\n",
    "    def __init__(self, srt_file_path):\n",
    "        self.srt_file_path = srt_file_path\n",
    "        self.frame_data = {}  # Dictionary to store frame data\n",
    "        self.parse_srt_file()\n",
    "    \n",
    "    def parse_srt_file(self):\n",
    "        \"\"\"Parse SRT file and store frame-wise data\"\"\"\n",
    "        with open(self.srt_file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Split content by double newline to separate frame entries\n",
    "        frame_entries = content.strip().split('\\n\\n')\n",
    "        \n",
    "        for entry in frame_entries:\n",
    "            # print(entry)\n",
    "            lines = entry.split('\\n') # list\n",
    "            # print(lines)\n",
    "            if len(lines) != 5:  # Each entry should have exactly 5 lines\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Line 1: Frame number\n",
    "                frame_number = int(lines[0])\n",
    "                # print(frame_number)\n",
    "                \n",
    "                # Line 2: Time code (not needed for now)\n",
    "                # time_code = lines[1]\n",
    "                \n",
    "                # Line 3: Frame count and diff time (not needed for now)\n",
    "                # frame_info = lines[2]\n",
    "                \n",
    "                # Line 4: Timestamp\n",
    "                timestamp = datetime.strptime(lines[3].split(',')[0], '%Y-%m-%d %H:%M:%S')\n",
    "                # print(timestamp)\n",
    "                \n",
    "                # Line 5: Drone data\n",
    "                drone_data = lines[4].replace('</font>', '')\n",
    "                # print(drone_data)\n",
    "                \n",
    "                # Parse drone data using regex\n",
    "                lat_match = re.search(r'latitude: ([-\\d.]+)', drone_data)\n",
    "                lon_match = re.search(r'longtitude: ([-\\d.]+)', drone_data)\n",
    "        \n",
    "                # rel_alt_match = re.search(r'rel_alt: ([-\\d.]+)', drone_data)\n",
    "                # abs_alt_match = re.search(r'abs_alt: ([-\\d.]+)', drone_data)\n",
    "                # yaw_match = re.search(r'Yaw:([-\\d.]+)', drone_data)\n",
    "                # pitch_match = re.search(r'Pitch:([-\\d.]+)', drone_data)\n",
    "                # roll_match = re.search(r'Roll:([-\\d.]+)', drone_data)\n",
    "                \n",
    "                # Store data\n",
    "                self.frame_data[frame_number] = {\n",
    "                    'timestamp': timestamp,\n",
    "                    'latitude': float(lat_match.group(1)) if lat_match else None,\n",
    "                    'longitude': float(lon_match.group(1)) if lon_match else None,\n",
    "                    # 'rel_altitude': float(rel_alt_match.group(1)) if rel_alt_match else None,\n",
    "                    # 'abs_altitude': float(abs_alt_match.group(1)) if abs_alt_match else None,\n",
    "                    # 'yaw': float(yaw_match.group(1)) if yaw_match else None,\n",
    "                    # 'pitch': float(pitch_match.group(1)) if pitch_match else None,\n",
    "                    # 'roll': float(roll_match.group(1)) if roll_match else None\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing frame {frame_number}: {str(e)}\")\n",
    "    \n",
    "    def get_frame_data(self, frame_number):\n",
    "        \"\"\"Get data for a specific frame\"\"\"\n",
    "        return self.frame_data.get(frame_number, None)\n",
    "\n",
    "\n",
    "class HotspotDetector:\n",
    "    def __init__(self, yolo_model_path):\n",
    "        # Load YOLO model\n",
    "        self.model = YOLO(yolo_model_path)\n",
    "        \n",
    "    def create_mask_from_yolo(self, image, results):\n",
    "        \"\"\"Create mask from YOLO detections\"\"\"\n",
    "        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "        \n",
    "        # Get masks from YOLO results\n",
    "        for result in results:\n",
    "            if result.masks is not None:\n",
    "                # Convert masks to numpy array\n",
    "                masks = result.masks.cpu().numpy()\n",
    "                for segment_mask in masks.data:\n",
    "                    # Add to final mask\n",
    "                    mask = cv2.bitwise_or(mask, (segment_mask * 255).astype(np.uint8))\n",
    "        \n",
    "        # Erode the mask to reduce width\n",
    "        kernel_size = 10  # Adjust this value to control how much to shrink\n",
    "        kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "        eroded_mask = cv2.erode(mask, kernel, iterations=1)\n",
    "        \n",
    "        # Optional: Clean up the mask\n",
    "        # This will remove very small isolated regions\n",
    "        kernel_clean = np.ones((3,3), np.uint8)\n",
    "        cleaned_mask = cv2.morphologyEx(eroded_mask, cv2.MORPH_OPEN, kernel_clean)\n",
    "        \n",
    "        return cleaned_mask\n",
    "    \n",
    "    def detect_hotspots(self, frame, mask):\n",
    "        \"\"\"Detect hotspots with improved filtering for thin rectangles and clustered regions\"\"\"\n",
    "        enhanced_image = self.enhance_contrast(frame)\n",
    "        gray = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2GRAY)\n",
    "        masked_gray = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "        \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(masked_gray, (3, 3), 0)\n",
    "        # Edge detection\n",
    "        edges = cv2.Canny(blurred, 50, 150) # Adjust threshold as needed\n",
    "\n",
    "        # Dilate edges to connect broken parts\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        # dilated_edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "        # close edges to form complete boundaries\n",
    "        # closed_edges = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "        # Find contours from edges\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        valid_hotspots = []\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area < 50:  # Minimum area threshold\n",
    "                continue\n",
    "            \n",
    "            # Get rotated rectangle properties\n",
    "            rect = cv2.minAreaRect(contour)\n",
    "            width = min(rect[1])\n",
    "            height = max(rect[1])\n",
    "            \n",
    "            # Filter out thin rectangles\n",
    "            if width > 0:\n",
    "                aspect_ratio = height / width\n",
    "                if aspect_ratio > 4:  # Filter very thin rectangles\n",
    "                    continue\n",
    "            \n",
    "            # Get contour properties\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            roi = masked_gray[y:y+h, x:x+w]\n",
    "            \n",
    "            if roi.size == 0:\n",
    "                continue\n",
    "            \n",
    "            # Calculate solidity (area ratio between contour and convex hull)\n",
    "            hull = cv2.convexHull(contour)\n",
    "            hull_area = cv2.contourArea(hull)\n",
    "            if hull_area > 0:\n",
    "                solidity = area / hull_area\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Calculate contrast with surrounding\n",
    "            # padding = 3\n",
    "            # x_start = max(0, x - padding)\n",
    "            # y_start = max(0, y - padding)\n",
    "            # x_end = min(masked_gray.shape[1], x + w + padding)\n",
    "            # y_end = min(masked_gray.shape[0], y + h + padding)\n",
    "            \n",
    "            # surrounding = masked_gray[y_start:y_end, x_start:x_end]\n",
    "            # contour_mask = np.zeros_like(surrounding)\n",
    "            # contour_shifted = contour - np.array([x_start, y_start])\n",
    "            # cv2.drawContours(contour_mask, [contour_shifted], -1, 255, -1)\n",
    "            \n",
    "            # # Calculate mean intensities\n",
    "            # hotspot_mean = np.mean(surrounding[contour_mask > 0])\n",
    "            # background_mask = (contour_mask == 0) & (surrounding > 0)\n",
    "            # if np.sum(background_mask) > 0:\n",
    "            #     background_mean = np.mean(surrounding[background_mask])\n",
    "            # else:\n",
    "            #     continue\n",
    "            \n",
    "            # Combined criteria for valid hotspots\n",
    "            is_valid_hotspot = (\n",
    "                # background_mean > 0 and\n",
    "                # (hotspot_mean / background_mean) > 1.2 and  # Contrast threshold\n",
    "                solidity > 0.7 and  # Shape compactness\n",
    "                area > 50 and  # Minimum size\n",
    "                area < 10000  # Maximum size (adjust as needed)\n",
    "            )\n",
    "            \n",
    "            if is_valid_hotspot:\n",
    "                # Verify edge strength\n",
    "                edge_mask = np.zeros_like(edges)\n",
    "                cv2.drawContours(edge_mask, [contour], -1, 255, -1)\n",
    "                edge_strength = np.mean(edges[edge_mask > 0])\n",
    "                \n",
    "                if edge_strength > 20:  # Adjust threshold for edge strength\n",
    "                    valid_hotspots.append(contour)\n",
    "        \n",
    "        # Optional: Merge nearby hotspots\n",
    "        if len(valid_hotspots) > 1:\n",
    "            merged_mask = np.zeros_like(edges)\n",
    "            cv2.drawContours(merged_mask, valid_hotspots, -1, 255, -1)\n",
    "            \n",
    "            # Dilate to connect nearby hotspots\n",
    "            merged_mask = cv2.dilate(merged_mask, kernel, iterations=1)\n",
    "            merged_mask = cv2.erode(merged_mask, kernel, iterations=1)\n",
    "            \n",
    "            # Find contours of merged regions\n",
    "            merged_contours, _ = cv2.findContours(merged_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Filter merged contours\n",
    "            final_hotspots = []\n",
    "            for contour in merged_contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area > 50:  # Minimum area for merged regions\n",
    "                    final_hotspots.append(contour)\n",
    "            \n",
    "            return final_hotspots\n",
    "        \n",
    "        return valid_hotspots\n",
    "    \n",
    "    def enhance_contrast(self, image):\n",
    "        \"\"\"Enhance image contrast using CLAHE\"\"\"\n",
    "        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        cl = clahe.apply(l)\n",
    "        enhanced = cv2.merge((cl, a, b))\n",
    "        return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def create_frame_with_gap(th_frame, op_frame, result_frame, gap_width=20):\n",
    "    \"\"\"Create a combined frame with a gap between the two frames\"\"\"\n",
    "    # Resize optical frame to match thermal frame dimensions\n",
    "    op_frame_resized = cv2.resize(op_frame, (640, 512), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Create a black frame with gap\n",
    "    combined_width = 640*3 + gap_width*2  # Added extra gap\n",
    "    combined_frame = np.zeros((512, combined_width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Copy the frames with gaps\n",
    "    combined_frame[:512, :640] = th_frame\n",
    "    combined_frame[:512, 640+gap_width:1280+gap_width] = result_frame\n",
    "    combined_frame[:512, 1280+gap_width*2:] = op_frame_resized\n",
    "    \n",
    "    return combined_frame\n",
    "\n",
    "def process_video(optical_video_path, thermal_video_path, srt_file_path, yolo_model_path, output_path=None):\n",
    "    # Initialize detector\n",
    "    detector = HotspotDetector(yolo_model_path)\n",
    "    srt_parser = SRTParser(srt_file_path)\n",
    "    \n",
    "    # Open both videos\n",
    "    optical_cap = cv2.VideoCapture(optical_video_path)\n",
    "    thermal_cap = cv2.VideoCapture(thermal_video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    frame_width = 640  # Fixed width for output\n",
    "    frame_height = 512  # Fixed height for output\n",
    "    fps = int(thermal_cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Calculate dimensions for output video (including gaps)\n",
    "    gap_width = 10\n",
    "    output_width = (frame_width * 3) + gap_width * 2\n",
    "    \n",
    "    # Initialize video writer if output path is specified\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (output_width, frame_height))\n",
    "    \n",
    "    # Process frames\n",
    "    frame_count = 0\n",
    "    cv2.namedWindow('Results', cv2.WINDOW_NORMAL)\n",
    "    while optical_cap.isOpened() and thermal_cap.isOpened():\n",
    "        ret_optical, optical_frame = optical_cap.read()\n",
    "        ret_thermal, thermal_frame = thermal_cap.read()\n",
    "        \n",
    "        if not ret_optical or not ret_thermal:\n",
    "            break\n",
    "        \n",
    "        # Resize thermal frame if needed\n",
    "        if thermal_frame.shape[:2] != (512, 640):\n",
    "            thermal_frame = cv2.resize(thermal_frame, (640, 512), interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Get GPS data for current frame\n",
    "        frame_data = srt_parser.get_frame_data(frame_count)\n",
    "        \n",
    "        if frame_count % 2 == 0:  # Process every other frame\n",
    "            # Run YOLO detection\n",
    "            results = detector.model(thermal_frame)\n",
    "            \n",
    "            # Create mask from YOLO detections\n",
    "            panel_mask = detector.create_mask_from_yolo(thermal_frame, results)\n",
    "            \n",
    "            # Detect hotspots\n",
    "            hotspot_contours = detector.detect_hotspots(thermal_frame, panel_mask)\n",
    "            \n",
    "            # Draw results\n",
    "            result_frame = thermal_frame.copy()\n",
    "            \n",
    "            # Create green overlay for panel mask\n",
    "            overlay = np.zeros_like(result_frame)\n",
    "            overlay[panel_mask > 0] = [255, 0, 0]  # Green color\n",
    "            \n",
    "            # Blend the overlay with the original frame\n",
    "            result_frame = cv2.addWeighted(result_frame, 1, overlay, 0.5, 0)\n",
    "            \n",
    "            # Draw hotspot contours in solid red\n",
    "            cv2.drawContours(result_frame, hotspot_contours, -1, (0, 0, 255), 2)\n",
    "            cv2.drawContours(optical_frame, hotspot_contours, -1, (0, 0, 255), 2)\n",
    "            \n",
    "            # Add labels\n",
    "            cv2.putText(thermal_frame, 'Original', (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(result_frame, 'Hotspot detection', (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add GPS information to optical frame\n",
    "            if frame_data:\n",
    "                gps_text = [\n",
    "                    f\"Lat: {frame_data['latitude']:.6f}\",\n",
    "                    f\"Lon: {frame_data['longitude']:.6f}\",\n",
    "                    f\"Time: {frame_data['timestamp']}\"\n",
    "                ]\n",
    "                \n",
    "                # Add black background for better text visibility\n",
    "                for i, text in enumerate(gps_text):\n",
    "                    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]\n",
    "                    cv2.rectangle(optical_frame,\n",
    "                                (10, frame_height - 30 - (i * 25)), \n",
    "                                (10 + text_size[0], frame_height - 10 - (i * 25)), \n",
    "                                (0, 0, 0), -1)\n",
    "                    cv2.putText(optical_frame, text,\n",
    "                            (10, frame_height - 15 - (i * 25)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            # Create combined frame with gap\n",
    "            combined_frame = create_frame_with_gap(thermal_frame, optical_frame, result_frame, gap_width)\n",
    "            \n",
    "            # Display frame\n",
    "            cv2.imshow('Results', combined_frame)\n",
    "            \n",
    "            # Write frame if output path is specified\n",
    "            if output_path:\n",
    "                out.write(combined_frame)\n",
    "            \n",
    "            # Break loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    \n",
    "    # Cleanup\n",
    "    optical_cap.release()\n",
    "    thermal_cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    OPTICAL_VIDEO_PATH = \"C:/Users/DELL/Desktop/irida kerala/Day 2/Main Office DAY 1 Remaining/DCIM/100MEDIA/DJI_0741_W.MP4\"\n",
    "    THERMAL_VIDEO_PATH = \"C:/Users/DELL/Desktop/irida kerala/Day 2/Main Office DAY 1 Remaining/DCIM/100MEDIA/DJI_0742_T.MP4\"\n",
    "    SRT_FILE_PATH = \"C:/Users/DELL/Desktop/irida kerala/Day 2/Main Office DAY 1 Remaining/DCIM/100MEDIA/DJI_0742_T.SRT\"\n",
    "    YOLO_MODEL_PATH = \"C:/Users/DELL/Desktop/model-share/train/weights/best.pt\"\n",
    "    OUTPUT_PATH = \"C:/Users/DELL/Desktop/model-share/outputkerala.MP4\"  # Optional\n",
    "    \n",
    "    process_video(OPTICAL_VIDEO_PATH, THERMAL_VIDEO_PATH, SRT_FILE_PATH, YOLO_MODEL_PATH, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
